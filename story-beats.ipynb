{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4750b17-3e17-4bea-ac92-0886ca139561",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1639528a-1137-4270-8c2b-b3ef481c427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4526c69-03c4-4a09-a494-a3f00d9c2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMPS_PATH = 'train/train/scene_timestamps'\n",
    "FEATURES_PATH = 'train/train/features'\n",
    "LABELS_PATH = 'train/train/labels'\n",
    "SUBTITLES_PATH = 'train/train/subtitles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a14a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2e1c0-23af-428c-8112-10f7e0d6806b",
   "metadata": {},
   "source": [
    "## Load timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c262fc-85fd-4f5d-8bd8-2b985c281b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(TIMESTAMPS_PATH):\n",
    "    files = os.listdir(TIMESTAMPS_PATH)\n",
    "    # remove australia because australia subtitles are in diffrent format than everything else\n",
    "    files.remove(\"tt0455824_australia_timestamps.csv\")\n",
    "else:\n",
    "    print(\"PATH DOES NOT EXIST!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb21fde-14d1-48e9-843d-adec49a4c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(file):\n",
    "    return file[10:-15]\n",
    "\n",
    "def get_movie_id(file):\n",
    "    return file[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f655f126-732d-4091-9b0d-131163ee17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = []\n",
    "for file in files:\n",
    "    # print(f\"file name: {file}\")\n",
    "    movie_name = get_movie_name(file)\n",
    "    movies.append(movie_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6315a7a-d497-4fd4-b13f-0d221a94634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csv(path, movie_name):\n",
    "    df = pd.read_csv(path)\n",
    "    df.rename(columns={\"Unnamed: 0\": \"scene_id\"}, inplace=True)\n",
    "    df[\"movie\"] = movie_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb08e613-fd7f-4f8b-80fa-9be899ef1a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>6499.655</td>\n",
       "      <td>6571.893</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>6589.161</td>\n",
       "      <td>6609.264</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>6629.701</td>\n",
       "      <td>6677.999</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>6682.504</td>\n",
       "      <td>6686.675</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start       end               movie\n",
       "3724       220  6499.655  6571.893  dallas buyers club\n",
       "3725       221  6574.396  6574.396  dallas buyers club\n",
       "3726       224  6589.161  6609.264  dallas buyers club\n",
       "3727       226  6629.701  6677.999  dallas buyers club\n",
       "3728       227  6682.504  6686.675  dallas buyers club"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for idx, file in enumerate(files):\n",
    "    timestamp_path = os.path.join(TIMESTAMPS_PATH, file)\n",
    "    df = prepare_csv(timestamp_path, movies[idx])\n",
    "    dfs.append(df)\n",
    "\n",
    "timestamps = pd.concat(dfs, ignore_index=True)\n",
    "print(timestamps.shape)\n",
    "timestamps.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbb423-7daf-4a2a-8a5d-cb6ec94259a9",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7d4cc6-cda7-4be3-b5f1-85ed26b1ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_file(file):\n",
    "    return file.replace(\"_timestamps\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9146b9-1976-47e1-82e4-697d4044dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files = []\n",
    "for file in files:\n",
    "    feature_file = get_feature_file(file)\n",
    "    feature_files.append(feature_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a942e6a9-a3b6-4094-af4c-fc5ce5e607d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>74.699333</td>\n",
       "      <td>16</td>\n",
       "      <td>4.668708</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>656.478716</td>\n",
       "      <td>1</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>372.108700</td>\n",
       "      <td>0</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>34.826333</td>\n",
       "      <td>6</td>\n",
       "      <td>5.804389</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>928.370357</td>\n",
       "      <td>1</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>52.761333</td>\n",
       "      <td>19</td>\n",
       "      <td>2.776912</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>1076.267498</td>\n",
       "      <td>1</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>5.672333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.418083</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>2085.459362</td>\n",
       "      <td>1</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id      s_dur  n_shots  ava_shot_dur  rel_id_loc  rel_t_loc  \\\n",
       "3724       220  74.699333       16      4.668708    0.960699   0.926278   \n",
       "3725       221   5.380333        1      5.380333    0.965066   0.936929   \n",
       "3726       224  34.826333        6      5.804389    0.978166   0.939033   \n",
       "3727       226  52.761333       19      2.776912    0.986900   0.944811   \n",
       "3728       227   5.672333        4      1.418083    0.991266   0.952336   \n",
       "\n",
       "      ava_char_score  is_prot_appear               movie  \n",
       "3724      656.478716               1  dallas buyers club  \n",
       "3725      372.108700               0  dallas buyers club  \n",
       "3726      928.370357               1  dallas buyers club  \n",
       "3727     1076.267498               1  dallas buyers club  \n",
       "3728     2085.459362               1  dallas buyers club  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for idx, file in enumerate(files):\n",
    "    feature_path = os.path.join(FEATURES_PATH, feature_files[idx])\n",
    "    df = prepare_csv(feature_path, movies[idx])\n",
    "    dfs.append(df)\n",
    "\n",
    "features = pd.concat(dfs, ignore_index=True)\n",
    "print(features.shape)\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d62e0-fcb5-479f-9e9c-7dc55dbad392",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a819c-9244-4014-bb3d-0e3182cb63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>label</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>Finale</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>Finale</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id        label               movie\n",
       "3724       220       Finale  dallas buyers club\n",
       "3725       221       Finale  dallas buyers club\n",
       "3726       224  Final Image  dallas buyers club\n",
       "3727       226  Final Image  dallas buyers club\n",
       "3728       227  Final Image  dallas buyers club"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for idx, file in enumerate(files):\n",
    "    # print(feature_files[idx])\n",
    "    labels_path = os.path.join(LABELS_PATH, feature_files[idx])\n",
    "    \n",
    "    df = pd.read_csv(labels_path, keep_default_na=False)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Unnamed: 0\": \"scene_id\",\n",
    "            \"0\": \"label\"\n",
    "        }, inplace=True\n",
    "    )\n",
    "    df[\"movie\"] = movies[idx]\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "labels = pd.concat(dfs, ignore_index=True)\n",
    "print(labels.shape)\n",
    "labels.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf534f-0205-4b3d-8779-3c3bf53ae04d",
   "metadata": {},
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaced6b2-e619-4134-80ea-932c5a7eb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>6499.655</td>\n",
       "      <td>6571.893</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>74.699333</td>\n",
       "      <td>16</td>\n",
       "      <td>4.668708</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>656.478716</td>\n",
       "      <td>1</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>372.108700</td>\n",
       "      <td>0</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>6589.161</td>\n",
       "      <td>6609.264</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>34.826333</td>\n",
       "      <td>6</td>\n",
       "      <td>5.804389</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>928.370357</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>6629.701</td>\n",
       "      <td>6677.999</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>52.761333</td>\n",
       "      <td>19</td>\n",
       "      <td>2.776912</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>1076.267498</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>6682.504</td>\n",
       "      <td>6686.675</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.672333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.418083</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>2085.459362</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start       end               movie      s_dur  n_shots  \\\n",
       "3724       220  6499.655  6571.893  dallas buyers club  74.699333       16   \n",
       "3725       221  6574.396  6574.396  dallas buyers club   5.380333        1   \n",
       "3726       224  6589.161  6609.264  dallas buyers club  34.826333        6   \n",
       "3727       226  6629.701  6677.999  dallas buyers club  52.761333       19   \n",
       "3728       227  6682.504  6686.675  dallas buyers club   5.672333        4   \n",
       "\n",
       "      ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  is_prot_appear  \\\n",
       "3724      4.668708    0.960699   0.926278      656.478716               1   \n",
       "3725      5.380333    0.965066   0.936929      372.108700               0   \n",
       "3726      5.804389    0.978166   0.939033      928.370357               1   \n",
       "3727      2.776912    0.986900   0.944811     1076.267498               1   \n",
       "3728      1.418083    0.991266   0.952336     2085.459362               1   \n",
       "\n",
       "            label  \n",
       "3724       Finale  \n",
       "3725       Finale  \n",
       "3726  Final Image  \n",
       "3727  Final Image  \n",
       "3728  Final Image  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps_features = pd.merge(timestamps, features, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "full_data = pd.merge(timestamps_features, labels, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "\n",
    "print(full_data.shape)\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831d8b3-95ac-449d-9dfc-83ff25f5fbfd",
   "metadata": {},
   "source": [
    "## Correct end column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fcb2f39-2263-4b87-9be2-f3a05dcaf462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>6499.655</td>\n",
       "      <td>6574.354333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>74.699333</td>\n",
       "      <td>16</td>\n",
       "      <td>4.668708</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>656.478716</td>\n",
       "      <td>1</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>6579.776333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>372.108700</td>\n",
       "      <td>0</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>6589.161</td>\n",
       "      <td>6623.987333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>34.826333</td>\n",
       "      <td>6</td>\n",
       "      <td>5.804389</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>928.370357</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>6629.701</td>\n",
       "      <td>6682.462333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>52.761333</td>\n",
       "      <td>19</td>\n",
       "      <td>2.776912</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>1076.267498</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>6682.504</td>\n",
       "      <td>6688.176333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.672333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.418083</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>2085.459362</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start          end               movie      s_dur  n_shots  \\\n",
       "3724       220  6499.655  6574.354333  dallas buyers club  74.699333       16   \n",
       "3725       221  6574.396  6579.776333  dallas buyers club   5.380333        1   \n",
       "3726       224  6589.161  6623.987333  dallas buyers club  34.826333        6   \n",
       "3727       226  6629.701  6682.462333  dallas buyers club  52.761333       19   \n",
       "3728       227  6682.504  6688.176333  dallas buyers club   5.672333        4   \n",
       "\n",
       "      ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  is_prot_appear  \\\n",
       "3724      4.668708    0.960699   0.926278      656.478716               1   \n",
       "3725      5.380333    0.965066   0.936929      372.108700               0   \n",
       "3726      5.804389    0.978166   0.939033      928.370357               1   \n",
       "3727      2.776912    0.986900   0.944811     1076.267498               1   \n",
       "3728      1.418083    0.991266   0.952336     2085.459362               1   \n",
       "\n",
       "            label  \n",
       "3724       Finale  \n",
       "3725       Finale  \n",
       "3726  Final Image  \n",
       "3727  Final Image  \n",
       "3728  Final Image  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[\"end\"] = full_data[\"start\"] + full_data[\"s_dur\"]\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c61e3-fdb8-45bd-9d9e-f47fff1e28fb",
   "metadata": {},
   "source": [
    "## Load subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eae068f-77ad-4d4e-a9e8-b22fa4f80c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c1aa39-bc40-47b7-b024-520ecd2cdc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0116695_jerry maguire.srt\n"
     ]
    }
   ],
   "source": [
    "subtitles_files = [file.replace('.csv', '.srt') for file in feature_files]\n",
    "print(subtitles_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2bc1421-41c6-4f33-a9de-3f92c0b5e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/train/subtitles\\tt0116695_jerry maguire.srt\n"
     ]
    }
   ],
   "source": [
    "subtitle_paths = [os.path.join(SUBTITLES_PATH, subtitle_file) for subtitle_file in subtitles_files]\n",
    "print(subtitle_paths[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e5c89a9-34e5-4954-b1ed-e85a1468cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subtitles = {}\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    movie_name = movies[idx]\n",
    "    movie_subtitles[movie_name] = []\n",
    "    # print(movie_name)\n",
    "\n",
    "    if movie_name == \"pretty woman\":\n",
    "        with open(subtitle_paths[idx], 'r', encoding='utf-16') as subtitle_file:\n",
    "            movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "    else:\n",
    "        with open(subtitle_paths[idx], 'r', encoding='utf-8') as subtitle_file:\n",
    "            movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ef27d9-bebd-4007-a744-029d2ca7d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sub_info(sub):\n",
    "    print(f\"Subtitle {idx + 1}\")\n",
    "    print(f\"Start Time: {sub.start.total_seconds()}\")\n",
    "    print(f\"End Time: {sub.end.total_seconds()}\")\n",
    "    print(f\"Text: {sub.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f08f684-b487-4003-999f-9b90413018f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE: the lost weekend\n",
      "Subtitle 1\n",
      "Start Time: 150.32\n",
      "End Time: 152.926\n",
      "Text: You'd better take this along, Don.\n",
      "It's gonna be cold on the farm.\n",
      "\n",
      "Subtitle 2\n",
      "Start Time: 153.04\n",
      "End Time: 154.963\n",
      "Text: - OK.\n",
      "- How many shirts are you taking?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_name = movies[0]\n",
    "print(f\"MOVIE: {movie_name}\")\n",
    "for idx, sub in enumerate(movie_subtitles[movie_name]):\n",
    "    print_sub_info(sub)\n",
    "\n",
    "    if idx == 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9534f79-6b1f-43d4-bdcd-cb052cc14f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored subtitltes: 3018\n"
     ]
    }
   ],
   "source": [
    "last_processed_subtitle_idx = 0\n",
    "movies_scenes_subtitles = {}\n",
    "missed_subtitles = 0\n",
    "\n",
    "for scene_idx, scene_row in full_data.iterrows():\n",
    "    scene_start = scene_row['start']\n",
    "    scene_end = scene_row['end']\n",
    "    scene_id = scene_row['scene_id']\n",
    "    movie_name = scene_row['movie']\n",
    "\n",
    "    # Create new dictionary for every movie\n",
    "    if movie_name not in movies_scenes_subtitles:\n",
    "        # print(f\"Movie: {movie_name}\")\n",
    "        # print(\"==================================================================\")\n",
    "        movies_scenes_subtitles[movie_name] = {}\n",
    "        last_processed_subtitle_idx = 0\n",
    "    \n",
    "    # print(f\"Scene: {scene_id}, Start Time - {scene_start}, End Time - {scene_end}\")\n",
    "        \n",
    "    # Craete new dictionary for every scene within movie\n",
    "    movies_scenes_subtitles[movie_name][scene_id] = []\n",
    "\n",
    "    current_movie_subtitles = movie_subtitles[movie_name]\n",
    "    for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n",
    "        sub = current_movie_subtitles[idx]\n",
    "        sub_start = sub.start.total_seconds()\n",
    "        sub_end = sub.end.total_seconds()\n",
    "        sub_content = sub.content\n",
    "\n",
    "        # Some subtitles start just before scene_start\n",
    "        if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n",
    "            # print(f\"Subtitle {idx + 1}: Start Time - {sub_start}, End Time - {sub_end}\")\n",
    "            # print(f\"{sub_content}\")\n",
    "\n",
    "            # Add subtitle content to the dictionary for the current scene\n",
    "            movies_scenes_subtitles[movie_name][scene_id].append(sub_content)\n",
    "            \n",
    "        elif scene_end < sub_end:\n",
    "            last_processed_subtitle_idx = idx\n",
    "            break\n",
    "        else:\n",
    "            missed_subtitles += 1\n",
    "            # print(f\"Scene: {scene_id}, Start Time - {scene_start}, End Time - {scene_end}\")\n",
    "            # print(f\"Subtitle {idx + 1}: Start Time - {sub_start}, End Time - {sub_end}\")\n",
    "            # print(f\"{sub_content}\")\n",
    "\n",
    "# I believe that subtitles are ignored for 2 reasons\n",
    "# 1. some subtitles start just before scene starts\n",
    "# 2. some scenes are missing from dataset\n",
    "print(f\"Ignored subtitltes: {missed_subtitles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11bf787c-9300-4255-8288-a8f15b8d44ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- And you have all four. Take a look.\\n- Oh!',\n",
       " \"But I wouldn't trust you with\\nreal gold. That's why this one's\\nonly worth about a penny.\",\n",
       " '- Hmm.\\n- And if you wonder where\\nthe other one went, watch.',\n",
       " 'Penny from the ear.\\nHow much for the rest?',\n",
       " \"- Have you seen Edward?\\n- No, I haven't. Great party, Philip.\",\n",
       " 'Well, my wife went to a lot of trouble.\\nShe called a caterer.',\n",
       " '- Excuse me, Anne. Howard, how are ya?\\n- Philip, good.',\n",
       " \"Hey, I understand Edward's\\ntaking over Morse Industries.\",\n",
       " \"- Yeah, well, he's not\\nhere to get a suntan.\\n- Can I get in on it?\",\n",
       " '- Yeah, call me.\\n- When?\\n- Just call me.',\n",
       " \"Uh, hi. I'm Philip Stuckey,\\nEdward Lewis' lawyer.\",\n",
       " \"- Hey, where's\\nthe guest of honour anyway?\\n- Well, if I know him,\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_scenes_subtitles['pretty woman'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0a6fe",
   "metadata": {},
   "source": [
    "## Subtitles cleaning and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d1034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- And you have all four. Take a look. - Oh! But I wouldn't trust you with real gold. That's why this one's only worth about a penny. - Hmm. - And if you wonder where the other one went, watch. Penny from the ear. How much for the rest? - Have you seen Edward? - No, I haven't. Great party, Philip. Well, my wife went to a lot of trouble. She called a caterer. - Excuse me, Anne. Howard, how are ya? - Philip, good. Hey, I understand Edward's taking over Morse Industries. - Yeah, well, he's not here to get a suntan. - Can I get in on it? - Yeah, call me. - When? - Just call me. Uh, hi. I'm Philip Stuckey, Edward Lewis' lawyer. - Hey, where's the guest of honour anyway? - Well, if I know him,\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "    for scene_id, subtitles in scenes.items():\n",
    "        cleaned_subtitles = []\n",
    "        for subtitle in subtitles:\n",
    "            # Remove new line characters\n",
    "            cleaned_subtitle = subtitle.replace('\\n', ' ').strip()\n",
    "            cleaned_subtitles.append(cleaned_subtitle)\n",
    "        combined_text = \" \".join(cleaned_subtitles)\n",
    "        movies_scenes_subtitles[movie_name][scene_id] = combined_text\n",
    "\n",
    "movies_scenes_subtitles['pretty woman'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cafdd5",
   "metadata": {},
   "source": [
    "## Tokenize and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98486364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# embeddings = []\n",
    "# for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "#     for scene_id, combined_text in scenes.items():\n",
    "#         inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}  # move tensors to GPU\n",
    "#         outputs = model(**inputs)\n",
    "#         embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().tolist() # move outputs to CPU\n",
    "#         movies_scenes_subtitles[movie_name][scene_id] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_scenes_subtitles['pretty woman'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e715b4",
   "metadata": {},
   "source": [
    "## Merge with Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "# for index, row in full_data.iterrows():\n",
    "#     movie_name = row['movie']\n",
    "#     scene_id = row['scene_id']\n",
    "    \n",
    "#     embedding = movies_scenes_subtitles.get(movie_name, {}).get(scene_id, None)\n",
    "    \n",
    "#     embeddings.append(embedding)\n",
    "\n",
    "# full_data.insert(full_data.columns.get_loc('label'), 'embedding', embeddings)\n",
    "# full_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334d013",
   "metadata": {},
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed7adb",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# full_data_clean = full_data.dropna()\n",
    "\n",
    "# embeddings = np.array(full_data_clean['embedding'].tolist())\n",
    "\n",
    "# X = full_data_clean[['s_dur', 'n_shots', 'ava_shot_dur', 'rel_id_loc', 'rel_t_loc', 'ava_char_score', 'is_prot_appear']]\n",
    "# X = np.hstack((X, embeddings))\n",
    "# y = full_data_clean['label']\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': [210, 240, 200, 225, 250],\n",
    "#     'min_samples_split': [15, 25, 35],\n",
    "#     'min_samples_leaf': [10, 15, 20],\n",
    "#     'max_depth': [10, 15, 20, 25, 30, 50]\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(RandomForestClassifier(random_state=23), param_distributions=param_dist, n_iter=10, cv=5, random_state=23, n_jobs=-1)\n",
    "# random_search.fit(X, y)\n",
    "\n",
    "# print(\"Best parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e338f7",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(random_state=23, n_estimators=200, min_samples_split=15, min_samples_leaf=20, max_depth=15)\n",
    "# model.fit(X, y)\n",
    "# y_pred = model.predict(X)\n",
    "# scores = cross_val_score(model, X, y, cv=5)\n",
    "# print(f\"Mean Accuracy from cross-validation: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff470f4-0400-4ec3-a8bc-aac7c47e08be",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e086559-82e7-44a9-a159-970d9dbd8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# _, levels = pd.factorize(full_data_clean['label'])\n",
    "# print(classification_report(y,y_pred,target_names=levels))\n",
    "\n",
    "# accuracy = accuracy_score(y, y_pred)\n",
    "# print()\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fc580-c101-41e6-b409-8fdf5003f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model', 'X', and 'y' are already defined\n",
    "# predicted = cross_val_predict(model, X, y, cv=5)\n",
    "# conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eff19d-1730-4609-afd1-e5ddc12c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12,10))\n",
    "# sns.heatmap(conf_matrix, fmt='g', ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a274c22",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b280aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddd1ea",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb207ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>scene</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>You'd better take this along, Don. It's gonna ...</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>1</td>\n",
       "      <td>Are you sure it's in the closet? I can't find ...</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>2</td>\n",
       "      <td>- Did you find it? - Oh, sure, sure. Here it i...</td>\n",
       "      <td>Set-Up</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>3</td>\n",
       "      <td>The new Thurber book with comical jokes and pi...</td>\n",
       "      <td>Set-Up</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>4</td>\n",
       "      <td>Nobody? What are they playing? Brahms' 2nd Sym...</td>\n",
       "      <td>Theme Stated</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              movie  scene                                               text  \\\n",
       "0  the lost weekend      0  You'd better take this along, Don. It's gonna ...   \n",
       "1  the lost weekend      1  Are you sure it's in the closet? I can't find ...   \n",
       "2  the lost weekend      2  - Did you find it? - Oh, sure, sure. Here it i...   \n",
       "3  the lost weekend      3  The new Thurber book with comical jokes and pi...   \n",
       "4  the lost weekend      4  Nobody? What are they playing? Brahms' 2nd Sym...   \n",
       "\n",
       "           label  encoded_label  \n",
       "0  Opening Image             13  \n",
       "1  Opening Image             13  \n",
       "2         Set-Up             14  \n",
       "3         Set-Up             14  \n",
       "4   Theme Stated             15  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for movie, scenes in movies_scenes_subtitles.items():\n",
    "    for scene_number, text in scenes.items():\n",
    "        data.append({\"movie\": movie, \"scene\": scene_number, \"text\": text})\n",
    "scenes_df = pd.DataFrame(data)\n",
    "\n",
    "combined_df = pd.concat([scenes_df, full_data['label']], axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['encoded_label'] = label_encoder.fit_transform(combined_df['label'])\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036b0dc",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a9229cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    combined_df['text'], combined_df['encoded_label'], random_state=23, test_size=0.3, stratify=combined_df['encoded_label'])\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, random_state=23, test_size=0.5, stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9d03f",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba43e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_texts(texts, labels):\n",
    "    encodings = tokenizer(texts.to_list(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(labels)\n",
    "    return encodings, labels\n",
    "\n",
    "train_encodings, train_labels = encode_texts(train_texts, train_labels.values)\n",
    "val_encodings, val_labels = encode_texts(val_texts, val_labels.values)\n",
    "test_encodings, test_labels = encode_texts(test_texts, test_labels.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e5fbe",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "507ffa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], \n",
    "                              train_encodings['attention_mask'], \n",
    "                              train_labels)\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], \n",
    "                            val_encodings['attention_mask'], \n",
    "                            val_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], \n",
    "                             test_encodings['attention_mask'], \n",
    "                             test_labels)\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b89e0",
   "metadata": {},
   "source": [
    "### Trening and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2bf9a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "def calculate_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Trening model\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t for t in batch)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        b_labels = b_labels.long()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t for t in batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Validation Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49408d5e",
   "metadata": {},
   "source": [
    "## Prepare testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TIMESTAMPS_PATH = 'test/test/scene_timestamps'\n",
    "TEST_FEATURES_PATH = 'test/test/features'\n",
    "TEST_SUBTITLES_PATH = 'test/test/subtitles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_files(path):\n",
    "    if os.path.exists(path):\n",
    "        return os.listdir(path)\n",
    "    else:\n",
    "        print(\"PATH DOES NOT EXIST!\")\n",
    "        return []\n",
    "\n",
    "def extract_movie_info(files):\n",
    "    movie_ids, movies = [], []\n",
    "    for file in files:\n",
    "        movie_name = get_movie_name(file)\n",
    "        movie_id = get_movie_id(file)\n",
    "        movie_ids.append(movie_id)\n",
    "        movies.append(movie_name)\n",
    "    return movie_ids, movies\n",
    "\n",
    "def prepare_dataframes(files, path_func, data_func):\n",
    "    dfs = []\n",
    "    for idx, file in enumerate(files):\n",
    "        path = path_func(file)\n",
    "        df = data_func(path, movies[idx])\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def merge_dataframes(df1, df2):\n",
    "    test_full_data = pd.merge(df1, df2, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "    test_full_data[\"end\"] = test_full_data[\"start\"] + test_full_data[\"s_dur\"]\n",
    "    return test_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = load_test_files(TEST_TIMESTAMPS_PATH)\n",
    "test_features_files = load_test_files(TEST_FEATURES_PATH)\n",
    "test_movies_ids, test_movies = extract_movie_info(test_files)\n",
    "\n",
    "test_timestamps = prepare_dataframes(test_files, \n",
    "                                     lambda file: os.path.join(TEST_TIMESTAMPS_PATH, file), \n",
    "                                     prepare_csv)\n",
    "\n",
    "test_features = prepare_dataframes(test_files, \n",
    "                                   lambda file: os.path.join(TEST_FEATURES_PATH, get_feature_file(file)), \n",
    "                                   prepare_csv)\n",
    "\n",
    "test_full_data = merge_dataframes(test_timestamps, test_features)\n",
    "\n",
    "print(test_full_data.shape)\n",
    "test_full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_files_to_subtitles(test_files):\n",
    "    return [file.replace('.csv', '.srt') for file in test_files]\n",
    "\n",
    "def load_subtitles(test_subtitle_paths, test_movies):\n",
    "    test_movie_subtitles = {}\n",
    "    for idx, movie_name in enumerate(test_movies):\n",
    "        print(idx)\n",
    "        with open(test_subtitle_paths[idx], 'r', encoding='utf-16') as subtitle_file:\n",
    "            test_movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "    return test_movie_subtitles\n",
    "\n",
    "def associate_scenes_with_subtitles(test_full_data, test_movie_subtitles):\n",
    "    test_movies_scenes_subtitles = {}\n",
    "    last_processed_subtitle_idx = 0\n",
    "\n",
    "    for scene_idx, scene_row in test_full_data.iterrows():\n",
    "        scene_start, scene_end = scene_row['start'], scene_row['end']\n",
    "        scene_id, movie_name = scene_row['scene_id'], scene_row['movie']\n",
    "        \n",
    "        if movie_name not in test_movies_scenes_subtitles:\n",
    "            test_movies_scenes_subtitles[movie_name] = {}\n",
    "            last_processed_subtitle_idx = 0\n",
    "\n",
    "        test_movies_scenes_subtitles[movie_name][scene_id] = []\n",
    "\n",
    "        current_movie_subtitles = test_movie_subtitles[movie_name]\n",
    "        for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n",
    "            sub = current_movie_subtitles[idx]\n",
    "            sub_start, sub_end = sub.start.total_seconds(), sub.end.total_seconds()\n",
    "\n",
    "            if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n",
    "                test_movies_scenes_subtitles[movie_name][scene_id].append(sub.content)\n",
    "            elif scene_end < sub_end:\n",
    "                last_processed_subtitle_idx = idx\n",
    "                break\n",
    "\n",
    "    return test_movies_scenes_subtitles\n",
    "\n",
    "def calculate_embeddings(test_movies_scenes_subtitles):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "    embeddings = {}\n",
    "    for movie_name, scenes in test_movies_scenes_subtitles.items():\n",
    "        for scene_id, combined_text in scenes.items():\n",
    "            inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "            embeddings.setdefault(movie_name, {})[scene_id] = embedding\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9947f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subtitles_files = convert_files_to_subtitles(test_features_files)\n",
    "test_subtitle_paths = [os.path.join(TEST_SUBTITLES_PATH, subtitle_file) for subtitle_file in test_subtitles_files]\n",
    "\n",
    "test_movie_subtitles = load_subtitles(test_subtitle_paths, test_movies)\n",
    "test_movies_scenes_subtitles = associate_scenes_with_subtitles(test_full_data, test_movie_subtitles)\n",
    "movies_scenes_embeddings = calculate_embeddings(test_movies_scenes_subtitles)\n",
    "\n",
    "embeddings = []\n",
    "for index, row in test_full_data.iterrows():\n",
    "    movie_name, scene_id = row['movie'], row['scene_id']\n",
    "    embedding = movies_scenes_embeddings.get(movie_name, {}).get(scene_id, None)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "test_full_data.insert(test_full_data.columns.get_loc('label'), 'embedding', embeddings)\n",
    "test_full_data.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
