{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4750b17-3e17-4bea-ac92-0886ca139561",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1639528a-1137-4270-8c2b-b3ef481c427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4526c69-03c4-4a09-a494-a3f00d9c2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMPS_PATH = 'train/train/scene_timestamps'\n",
    "FEATURES_PATH = 'train/train/features'\n",
    "LABELS_PATH = 'train/train/labels'\n",
    "SUBTITLES_PATH = 'train/train/subtitles'\n",
    "\n",
    "TEST_TIMESTAMPS_PATH = 'test/test/scene_timestamps'\n",
    "TEST_FEATURES_PATH = 'test/test/features'\n",
    "TEST_SUBTITLES_PATH = 'test/test/subtitles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a14a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000a3d5-7031-41ca-8e30-21753aacfbb6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2e1c0-23af-428c-8112-10f7e0d6806b",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac399c52-72f6-4643-be29-7f922e00447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    if os.path.exists(path):\n",
    "        return os.listdir(path)\n",
    "    else:\n",
    "        print(\"PATH DOES NOT EXIST!\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb21fde-14d1-48e9-843d-adec49a4c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(file):\n",
    "    return file[10:-15]\n",
    "\n",
    "def get_movie_id(file):\n",
    "    return file[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536fd822-2c92-493b-b3d6-b13fa53a725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_file(file):\n",
    "    return file.replace(\"_timestamps\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6315a7a-d497-4fd4-b13f-0d221a94634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csv(path, movie_name):\n",
    "    df = pd.read_csv(path)\n",
    "    df.rename(columns={\"Unnamed: 0\": \"scene_id\"}, inplace=True)\n",
    "    df[\"movie\"] = movie_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487bbef4-02d3-4e56-b7df-d2abacfb907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_info(files):\n",
    "    movie_ids, movies = [], []\n",
    "    for file in files:\n",
    "        movie_name = get_movie_name(file)\n",
    "        movie_id = get_movie_id(file)\n",
    "        movie_ids.append(movie_id)\n",
    "        movies.append(movie_name)\n",
    "    return movie_ids, movies\n",
    "\n",
    "def prepare_dataframes(files, movies, path_func, data_func):\n",
    "    dfs = []\n",
    "    for idx, file in enumerate(files):\n",
    "        path = path_func(file)\n",
    "        df = data_func(path, movies[idx])\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def merge_dataframes(df1, df2):\n",
    "    test_full_data = pd.merge(df1, df2, on=[\"scene_id\", \"movie\"])\n",
    "    test_full_data[\"end\"] = test_full_data[\"start\"] + test_full_data[\"s_dur\"]\n",
    "    return test_full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859a0bf-eda8-445d-8c8a-4d166393b1c9",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2fabdc-1f16-4dfb-9b0d-e761b72e231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = load_files(TIMESTAMPS_PATH)\n",
    "# remove australia because australia subtitles are in diffrent format than everything else\n",
    "train_files.remove(\"tt0455824_australia_timestamps.csv\")\n",
    "\n",
    "test_files = load_files(TEST_TIMESTAMPS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd91cd-a851-4157-9860-850ad3737162",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6798481c-e78e-4f88-87ea-4a0fa6451f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_ids, train_movies = extract_movie_info(train_files)\n",
    "test_movies_ids, test_movies = extract_movie_info(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f59cca-5f69-44f2-9246-539cce0e99ae",
   "metadata": {},
   "source": [
    "### Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51c99ee-7ffc-4df7-9c7c-932e7343bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps = prepare_dataframes(\n",
    "    train_files,\n",
    "    train_movies,\n",
    "    lambda file: os.path.join(TIMESTAMPS_PATH, file), \n",
    "    prepare_csv\n",
    ")\n",
    "\n",
    "test_timestamps = prepare_dataframes(\n",
    "    test_files,\n",
    "    test_movies,\n",
    "    lambda file: os.path.join(TEST_TIMESTAMPS_PATH, file), \n",
    "    prepare_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2befcf-73ce-4bde-8e7f-febf7891d147",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc254cd7-894b-4afa-9f26-c31b3974db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = prepare_dataframes(\n",
    "    train_files,\n",
    "    train_movies,\n",
    "    lambda file: os.path.join(FEATURES_PATH, get_feature_file(file)), \n",
    "    prepare_csv\n",
    ")\n",
    "\n",
    "test_features = prepare_dataframes(\n",
    "    test_files,\n",
    "    test_movies,\n",
    "    lambda file: os.path.join(TEST_FEATURES_PATH, get_feature_file(file)), \n",
    "    prepare_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467b2d-3432-42a9-964c-226ac931c302",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b36a21f1-9d62-4a9f-a51f-c355a49a96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for idx, file in enumerate(train_files):\n",
    "    # print(feature_files[idx])\n",
    "    labels_path = os.path.join(LABELS_PATH, get_feature_file(file))\n",
    "    \n",
    "    df = pd.read_csv(labels_path, keep_default_na=False)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Unnamed: 0\": \"scene_id\",\n",
    "            \"0\": \"label\"\n",
    "        }, inplace=True\n",
    "    )\n",
    "    df[\"movie\"] = train_movies[idx]\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "train_labels = pd.concat(dfs, ignore_index=True)\n",
    "# print(train_labels.shape)\n",
    "# train_labels.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d9296-bf27-47ed-8a17-9aa1f7773a7d",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794727e1-b58f-4d9f-ba31-2aab8901196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 12)\n",
      "(2470, 11)\n"
     ]
    }
   ],
   "source": [
    "train_merged = merge_dataframes(train_timestamps, train_features)\n",
    "# additionaly merge labels to train data\n",
    "train_full_data = pd.merge(train_merged, train_labels, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "print(train_full_data.shape)\n",
    "\n",
    "test_full_data = merge_dataframes(test_timestamps, test_features)\n",
    "print(test_full_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c61e3-fdb8-45bd-9d9e-f47fff1e28fb",
   "metadata": {},
   "source": [
    "## Join Scenes with subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70dc66ea-b37c-47aa-87b7-94c0e4c754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b2751-a43c-4cf1-9b6b-6ea8e573fc1e",
   "metadata": {},
   "source": [
    "### Helper runctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6768479e-06be-4fff-935f-7424174598ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_movies = [\"the ugly truth\", \"the social network\", \"the girl with the dragon tattoo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21b168cf-f6f1-429e-92ae-0f0f4e31033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_files_to_subtitles(files):\n",
    "    return [file.replace('.csv', '.srt') for file in files]\n",
    "\n",
    "def load_subtitles(paths, movies):\n",
    "    movie_subtitles = {}\n",
    "    for idx, movie_name in enumerate(movies):\n",
    "        # print(movie_name)\n",
    "        \n",
    "        if movie_name == \"pretty woman\":\n",
    "            with open(paths[idx], 'r', encoding='utf-16') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "        elif movie_name in problematic_movies:\n",
    "            with open(paths[idx], 'r', encoding='utf-8', errors='replace') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "        else:\n",
    "            with open(paths[idx], 'r', encoding='utf-8') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "                \n",
    "    return movie_subtitles\n",
    "\n",
    "def associate_scenes_with_subtitles(full_data, movie_subtitles):\n",
    "    movies_scenes_subtitles = {}\n",
    "    last_processed_subtitle_idx = 0\n",
    "    missed_subtitles = 0\n",
    "\n",
    "    for scene_idx, scene_row in full_data.iterrows():\n",
    "        scene_start, scene_end = scene_row['start'], scene_row['end']\n",
    "        scene_id, movie_name = scene_row['scene_id'], scene_row['movie']\n",
    "        \n",
    "        # Create new dictionary for every movie\n",
    "        if movie_name not in movies_scenes_subtitles:\n",
    "            movies_scenes_subtitles[movie_name] = {}\n",
    "            last_processed_subtitle_idx = 0\n",
    "\n",
    "        # Craete new dictionary for every scene within movie\n",
    "        movies_scenes_subtitles[movie_name][scene_id] = []\n",
    "\n",
    "        current_movie_subtitles = movie_subtitles[movie_name]\n",
    "        for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n",
    "            sub = current_movie_subtitles[idx]\n",
    "            sub_start, sub_end = sub.start.total_seconds(), sub.end.total_seconds()\n",
    "\n",
    "            # Some subtitles start just before scene_start\n",
    "            if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n",
    "                # Add subtitle content to the dictionary for the current scene\n",
    "                movies_scenes_subtitles[movie_name][scene_id].append(sub.content)\n",
    "            elif scene_end < sub_end:\n",
    "                last_processed_subtitle_idx = idx\n",
    "                break\n",
    "            else:\n",
    "                missed_subtitles += 1\n",
    "\n",
    "    print(f\"Ignored subtitltes: {missed_subtitles}\")\n",
    "    return movies_scenes_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb2a42-e9e0-4b51-8851-6f3c3989e397",
   "metadata": {},
   "source": [
    "### Get subtitle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe0cf7b-cb14-4eb1-a65d-376ce385faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_files = load_files(FEATURES_PATH)\n",
    "# remove australia because australia subtitles are in diffrent format than everything else\n",
    "train_features_files.remove('tt0455824_australia.csv')\n",
    "test_features_files = load_files(TEST_FEATURES_PATH)\n",
    "\n",
    "train_subtitles_files = convert_files_to_subtitles(train_features_files)\n",
    "train_subtitle_paths = [os.path.join(SUBTITLES_PATH, subtitle_file) for subtitle_file in train_subtitles_files]\n",
    "\n",
    "test_subtitles_files = convert_files_to_subtitles(test_features_files)\n",
    "test_subtitle_paths = [os.path.join(TEST_SUBTITLES_PATH, subtitle_file) for subtitle_file in test_subtitles_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49999294-c505-4b00-a2be-0f8a5c24ff3e",
   "metadata": {},
   "source": [
    "### Load subtitles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c910f57-e1ec-4562-9f27-92e13cc52825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_subtitles = load_subtitles(train_subtitle_paths, train_movies)\n",
    "test_movie_subtitles = load_subtitles(test_subtitle_paths, test_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad00e5-ee25-4e9d-85de-44e39278862d",
   "metadata": {},
   "source": [
    "### Associate Scenes with subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c1dd419-8d7d-4c19-9d8d-74f5588d0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored subtitltes: 3018\n",
      "Ignored subtitltes: 3165\n"
     ]
    }
   ],
   "source": [
    "train_movies_scenes_subtitles = associate_scenes_with_subtitles(train_full_data, train_movie_subtitles)\n",
    "test_movies_scenes_subtitles = associate_scenes_with_subtitles(test_full_data, test_movie_subtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0a6fe",
   "metadata": {},
   "source": [
    "## Subtitles cleaning and combining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6281799-8ce1-4208-92ce-efe2058c4bd1",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbfc8d6b-af1f-4df9-a109-4813387446b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subtitles(movies_scenes_subtitles):\n",
    "    for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "        for scene_id, subtitles in scenes.items():\n",
    "            cleaned_subtitles = []\n",
    "            for subtitle in subtitles:\n",
    "                # Remove new line characters\n",
    "                cleaned_subtitle = subtitle.replace('\\n', ' ').strip()\n",
    "                cleaned_subtitle = re.sub(r'<.*?>', '', cleaned_subtitle)\n",
    "                cleaned_subtitle = re.sub(r'♪', '', cleaned_subtitle)\n",
    "                cleaned_subtitles.append(cleaned_subtitle)\n",
    "            \n",
    "            combined_text = \" \".join(cleaned_subtitles)\n",
    "            movies_scenes_subtitles[movie_name][scene_id] = combined_text\n",
    "            \n",
    "    return movies_scenes_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4d1034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Although I can't dismiss   The memory of her kiss   I guess he's not for me \""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_movies_scenes_subtitles = clean_subtitles(train_movies_scenes_subtitles)\n",
    "clean_train_movies_scenes_subtitles['four weddings and a funeral'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48092566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"His majesty prefers not to be moistened. I got you a present. Oh. I hated this game. You loved it. You loved it. Thank you. I'll add it to the collection. Can you pour me a bourbon? (SIGHS) What's up, Jitters? (BREATHES DEEPLY) Well, if you're not going to talk... I'm gonna have to fill the silence... with another excruciating story by Margo Dunne. I could tell you about my recent customer service experience... changing Internet service providers. I like that one. Or how about the time... I saw that woman who looked exactly like my friend Monica? But it wasn't Monica. It was a total stranger. Who was also named Monica. Made it kind of interesting. It's great. I'm just having a bad day. Amy? It's our anniversary. Five years. Five? That came fast. And furious.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_movies_scenes_subtitles = clean_subtitles(test_movies_scenes_subtitles)\n",
    "clean_test_movies_scenes_subtitles['gone girl'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cafdd5",
   "metadata": {},
   "source": [
    "## Tokenize and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e0ad5-cd9a-4044-bfdf-237fd0e06f58",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "847ea61b-7aaa-4e5e-9159-12e90fbe2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a44eb11b-52c0-47cf-bbdc-fef38ae1467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(movies_scenes_subtitles):\n",
    "    embeddings = {}\n",
    "    for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "        for scene_id, combined_text in scenes.items():\n",
    "            inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "            embeddings.setdefault(movie_name, {})[scene_id] = embedding\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8b776d9-c0ca-4228-8052-922d49878988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      scene_id     start          end               movie      s_dur  n_shots  \\\n",
      "3724       220  6499.655  6574.354333  dallas buyers club  74.699333       16   \n",
      "3725       221  6574.396  6579.776333  dallas buyers club   5.380333        1   \n",
      "3726       224  6589.161  6623.987333  dallas buyers club  34.826333        6   \n",
      "3727       226  6629.701  6682.462333  dallas buyers club  52.761333       19   \n",
      "3728       227  6682.504  6688.176333  dallas buyers club   5.672333        4   \n",
      "\n",
      "      ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  is_prot_appear  \\\n",
      "3724      4.668708    0.960699   0.926278      656.478716               1   \n",
      "3725      5.380333    0.965066   0.936929      372.108700               0   \n",
      "3726      5.804389    0.978166   0.939033      928.370357               1   \n",
      "3727      2.776912    0.986900   0.944811     1076.267498               1   \n",
      "3728      1.418083    0.991266   0.952336     2085.459362               1   \n",
      "\n",
      "                                              embedding        label  \n",
      "3724  [0.031814076006412506, 0.13735561072826385, 0....       Finale  \n",
      "3725  [0.20158791542053223, 0.11704117059707642, 0.2...       Finale  \n",
      "3726  [0.31051069498062134, 0.047210514545440674, -0...  Final Image  \n",
      "3727  [0.051616448909044266, -0.009972741827368736, ...  Final Image  \n",
      "3728  [0.36869367957115173, 0.02289198897778988, 0.2...  Final Image  \n"
     ]
    }
   ],
   "source": [
    "train_movies_scenes_embeddings = calculate_embeddings(clean_train_movies_scenes_subtitles)\n",
    "\n",
    "train_embeddings = []\n",
    "for index, row in train_full_data.iterrows():\n",
    "    movie_name, scene_id = row['movie'], row['scene_id']\n",
    "    embedding = train_movies_scenes_embeddings.get(movie_name, {}).get(scene_id, None)\n",
    "    train_embeddings.append(embedding)\n",
    "\n",
    "train_full_data.insert(train_full_data.columns.get_loc('label'), 'embedding', train_embeddings)\n",
    "train_full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a282e8fe-0f92-4d39-96e9-a40ac5548f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>216</td>\n",
       "      <td>8437.638</td>\n",
       "      <td>8460.952333</td>\n",
       "      <td>gone girl</td>\n",
       "      <td>23.314333</td>\n",
       "      <td>10</td>\n",
       "      <td>2.331433</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.943599</td>\n",
       "      <td>1400.736946</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.06389163434505463, 0.051358889788389206, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>217</td>\n",
       "      <td>8460.994</td>\n",
       "      <td>8543.284333</td>\n",
       "      <td>gone girl</td>\n",
       "      <td>82.290333</td>\n",
       "      <td>20</td>\n",
       "      <td>4.114517</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>0.946211</td>\n",
       "      <td>1400.736946</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.20144830644130707, 0.04715737700462341, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>218</td>\n",
       "      <td>8543.326</td>\n",
       "      <td>8565.640333</td>\n",
       "      <td>gone girl</td>\n",
       "      <td>22.314333</td>\n",
       "      <td>8</td>\n",
       "      <td>2.789292</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.955418</td>\n",
       "      <td>1400.736946</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.384894460439682, 0.03037167154252529, 0.264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>219</td>\n",
       "      <td>8565.682</td>\n",
       "      <td>8607.307333</td>\n",
       "      <td>gone girl</td>\n",
       "      <td>41.625333</td>\n",
       "      <td>9</td>\n",
       "      <td>4.625037</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.957918</td>\n",
       "      <td>1094.344390</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.07813608646392822, -0.12171435356140137, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>220</td>\n",
       "      <td>8607.349</td>\n",
       "      <td>8649.390333</td>\n",
       "      <td>gone girl</td>\n",
       "      <td>42.041333</td>\n",
       "      <td>6</td>\n",
       "      <td>7.006889</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.962578</td>\n",
       "      <td>1029.305716</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4052170515060425, 0.03550687059760094, 0.22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start          end      movie      s_dur  n_shots  \\\n",
       "2465       216  8437.638  8460.952333  gone girl  23.314333       10   \n",
       "2466       217  8460.994  8543.284333  gone girl  82.290333       20   \n",
       "2467       218  8543.326  8565.640333  gone girl  22.314333        8   \n",
       "2468       219  8565.682  8607.307333  gone girl  41.625333        9   \n",
       "2469       220  8607.349  8649.390333  gone girl  42.041333        6   \n",
       "\n",
       "      ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  is_prot_appear  \\\n",
       "2465      2.331433    0.972973   0.943599     1400.736946               1   \n",
       "2466      4.114517    0.977477   0.946211     1400.736946               1   \n",
       "2467      2.789292    0.981982   0.955418     1400.736946               1   \n",
       "2468      4.625037    0.986486   0.957918     1094.344390               1   \n",
       "2469      7.006889    0.990991   0.962578     1029.305716               1   \n",
       "\n",
       "                                              embedding  \n",
       "2465  [-0.06389163434505463, 0.051358889788389206, 0...  \n",
       "2466  [0.20144830644130707, 0.04715737700462341, 0.2...  \n",
       "2467  [0.384894460439682, 0.03037167154252529, 0.264...  \n",
       "2468  [0.07813608646392822, -0.12171435356140137, 0....  \n",
       "2469  [0.4052170515060425, 0.03550687059760094, 0.22...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_movies_scenes_embeddings = calculate_embeddings(test_movies_scenes_subtitles)\n",
    "\n",
    "test_embeddings = []\n",
    "for index, row in test_full_data.iterrows():\n",
    "    movie_name, scene_id = row['movie'], row['scene_id']\n",
    "    embedding = test_movies_scenes_embeddings.get(movie_name, {}).get(scene_id, None)\n",
    "    test_embeddings.append(embedding)\n",
    "\n",
    "test_full_data['embedding'] = test_embeddings\n",
    "test_full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98486364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "# for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "#     for scene_id, combined_text in scenes.items():\n",
    "#         inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}  # move tensors to GPU\n",
    "#         outputs = model(**inputs)\n",
    "#         embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().tolist() # move outputs to CPU\n",
    "#         movies_scenes_subtitles[movie_name][scene_id] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e715b4",
   "metadata": {},
   "source": [
    "## Merge with Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366b0d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "# for index, row in full_data.iterrows():\n",
    "#     movie_name = row['movie']\n",
    "#     scene_id = row['scene_id']\n",
    "    \n",
    "#     embedding = movies_scenes_subtitles.get(movie_name, {}).get(scene_id, None)\n",
    "    \n",
    "#     embeddings.append(embedding)\n",
    "\n",
    "# full_data.insert(full_data.columns.get_loc('label'), 'embedding', embeddings)\n",
    "# full_data.tail()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = []\n",
    "for movie, scenes in movies_scenes_subtitles.items():\n",
    "    for scene_number, text in scenes.items():\n",
    "        data.append({\"movie\": movie, \"scene\": scene_number, \"text\": text})\n",
    "scenes_df = pd.DataFrame(data)\n",
    "\n",
    "full_data.insert(full_data.columns.get_loc('label'), 'text', scenes_df['text'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "full_data['encoded_label'] = label_encoder.fit_transform(full_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334d013",
   "metadata": {},
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed7adb",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f292ba62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 210, 'min_samples_split': 25, 'min_samples_leaf': 15, 'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# full_data_clean = full_data.dropna()\n",
    "\n",
    "embeddings = np.array(train_full_data['embedding'].tolist())\n",
    "\n",
    "X = train_full_data[['s_dur', 'n_shots', 'ava_shot_dur', 'rel_id_loc', 'rel_t_loc', 'ava_char_score', 'is_prot_appear']]\n",
    "X = np.hstack((X, embeddings))\n",
    "y = train_full_data['label']\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [210, 240, 200, 225, 250],\n",
    "    'min_samples_split': [15, 25, 35],\n",
    "    'min_samples_leaf': [10, 15, 20],\n",
    "    'max_depth': [10, 15, 20, 25, 30, 50]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=23), param_distributions=param_dist, n_iter=10, cv=5, random_state=23, n_jobs=-1)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e338f7",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "608c4a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy from cross-validation: 0.3818755960199363\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=23, n_estimators=210, min_samples_split=25, min_samples_leaf=15, max_depth=25)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Mean Accuracy from cross-validation: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff470f4-0400-4ec3-a8bc-aac7c47e08be",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e086559-82e7-44a9-a159-970d9dbd8171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         Opening Image       0.00      0.00      0.00        69\n",
      "                Set-Up       0.71      0.92      0.80       426\n",
      "          Theme Stated       0.93      0.88      0.90       345\n",
      "              Catalyst       0.00      0.00      0.00        92\n",
      "                Debate       0.00      0.00      0.00        81\n",
      "                  None       0.00      0.00      0.00        72\n",
      "        Break into Two       1.00      0.07      0.13       146\n",
      "               B Story       0.97      0.55      0.70       232\n",
      "              Midpoint       0.00      0.00      0.00        85\n",
      "     Bad Guys Close In       0.68      1.00      0.81       611\n",
      "           All Is Lost       0.96      0.89      0.92       370\n",
      "Dark Night of the Soul       0.00      0.00      0.00       102\n",
      "      Break into Three       0.59      0.90      0.72       521\n",
      "                Finale       0.00      0.00      0.00        64\n",
      "           Final Image       0.68      0.96      0.79       488\n",
      "         Fun and Games       0.00      0.00      0.00        25\n",
      "\n",
      "              accuracy                           0.73      3729\n",
      "             macro avg       0.41      0.38      0.36      3729\n",
      "          weighted avg       0.65      0.73      0.65      3729\n",
      "\n",
      "\n",
      "Accuracy: 0.7256637168141593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateusz\\miniconda3\\envs\\zed\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mateusz\\miniconda3\\envs\\zed\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mateusz\\miniconda3\\envs\\zed\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "_, levels = pd.factorize(train_full_data['label'])\n",
    "print(classification_report(y,y_pred,target_names=levels))\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fc580-c101-41e6-b409-8fdf5003f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model', 'X', and 'y' are already defined\n",
    "predicted = cross_val_predict(model, X, y, cv=5)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eff19d-1730-4609-afd1-e5ddc12c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "sns.heatmap(conf_matrix, fmt='g', ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a274c22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b280aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Studia\\Sem2-mgr\\ZED\\story-beats\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036b0dc",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a9229cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_data.drop(columns=['movie', 'encoded_label'])\n",
    "y = full_data['encoded_label']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, random_state=23, test_size=0.3, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, random_state=23, test_size=0.5, stratify=y_temp)\n",
    "\n",
    "train_texts = X_train['text']\n",
    "val_texts = X_val['text']\n",
    "test_texts = X_test['text']\n",
    "\n",
    "train_labels = y_train\n",
    "val_labels = y_val\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9d03f",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba43e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def encode_texts(texts, labels):\n",
    "    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(labels)\n",
    "    return encodings, labels\n",
    "\n",
    "train_encodings, train_labels = encode_texts(train_texts, train_labels.values)\n",
    "val_encodings, val_labels = encode_texts(val_texts, val_labels.values)\n",
    "test_encodings, test_labels = encode_texts(test_texts, test_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e5fbe",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e24a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  1,  9,  ...,  1,  9,  9], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "507ffa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], \n",
    "                              train_encodings['attention_mask'], \n",
    "                              train_labels)\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], \n",
    "                            val_encodings['attention_mask'], \n",
    "                            val_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], \n",
    "                             test_encodings['attention_mask'], \n",
    "                             test_labels)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b89e0",
   "metadata": {},
   "source": [
    "### Trening and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bf9a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\User\\Desktop\\Studia\\Sem2-mgr\\ZED\\story-beats\\venv\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 - Loss: 2.4764768867361235\n",
      "Epoch 1/12 - Validation Accuracy: 0.1625\n",
      "Epoch 2/12 - Loss: 2.446542373842704\n",
      "Epoch 2/12 - Validation Accuracy: 0.1529761904761905\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_encoder.classes_))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "def calculate_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Trening Model\n",
    "epochs = 12\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        b_labels = b_labels.long()\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Validation Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc500a76",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6672e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_test_accuracy = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_test_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "avg_test_accuracy = total_test_accuracy / len(test_loader)\n",
    "print(f'Test Accuracy: {avg_test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49408d5e",
   "metadata": {},
   "source": [
    "## Prepare testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f9776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9947f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
