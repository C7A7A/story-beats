{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4750b17-3e17-4bea-ac92-0886ca139561",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1639528a-1137-4270-8c2b-b3ef481c427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4526c69-03c4-4a09-a494-a3f00d9c2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMPS_PATH = 'train/train/scene_timestamps'\n",
    "FEATURES_PATH = 'train/train/features'\n",
    "LABELS_PATH = 'train/train/labels'\n",
    "SUBTITLES_PATH = 'train/train/subtitles'\n",
    "\n",
    "TEST_TIMESTAMPS_PATH = 'test/test/scene_timestamps'\n",
    "TEST_FEATURES_PATH = 'test/test/features'\n",
    "TEST_SUBTITLES_PATH = 'test/test/subtitles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09a14a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000a3d5-7031-41ca-8e30-21753aacfbb6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2e1c0-23af-428c-8112-10f7e0d6806b",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac399c52-72f6-4643-be29-7f922e00447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    if os.path.exists(path):\n",
    "        return os.listdir(path)\n",
    "    else:\n",
    "        print(\"PATH DOES NOT EXIST!\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccb21fde-14d1-48e9-843d-adec49a4c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(file):\n",
    "    return file[10:-15]\n",
    "\n",
    "def get_movie_id(file):\n",
    "    return file[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "536fd822-2c92-493b-b3d6-b13fa53a725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_file(file):\n",
    "    return file.replace(\"_timestamps\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6315a7a-d497-4fd4-b13f-0d221a94634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csv(path, movie_name):\n",
    "    df = pd.read_csv(path)\n",
    "    df.rename(columns={\"Unnamed: 0\": \"scene_id\"}, inplace=True)\n",
    "    df[\"movie\"] = movie_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "487bbef4-02d3-4e56-b7df-d2abacfb907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_info(files):\n",
    "    movie_ids, movies = [], []\n",
    "    for file in files:\n",
    "        movie_name = get_movie_name(file)\n",
    "        movie_id = get_movie_id(file)\n",
    "        movie_ids.append(movie_id)\n",
    "        movies.append(movie_name)\n",
    "    return movie_ids, movies\n",
    "\n",
    "def prepare_dataframes(files, movies, path_func, data_func):\n",
    "    dfs = []\n",
    "    for idx, file in enumerate(files):\n",
    "        path = path_func(file)\n",
    "        df = data_func(path, movies[idx])\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def merge_dataframes(df1, df2):\n",
    "    test_full_data = pd.merge(df1, df2, on=[\"scene_id\", \"movie\"])\n",
    "    test_full_data[\"end\"] = test_full_data[\"start\"] + test_full_data[\"s_dur\"]\n",
    "    return test_full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859a0bf-eda8-445d-8c8a-4d166393b1c9",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a2fabdc-1f16-4dfb-9b0d-e761b72e231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = load_files(TIMESTAMPS_PATH)\n",
    "# remove australia because australia subtitles are in diffrent format than everything else\n",
    "train_files.remove(\"tt0455824_australia_timestamps.csv\")\n",
    "\n",
    "test_files = load_files(TEST_TIMESTAMPS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd91cd-a851-4157-9860-850ad3737162",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6798481c-e78e-4f88-87ea-4a0fa6451f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_ids, train_movies = extract_movie_info(train_files)\n",
    "test_movies_ids, test_movies = extract_movie_info(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f59cca-5f69-44f2-9246-539cce0e99ae",
   "metadata": {},
   "source": [
    "### Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b51c99ee-7ffc-4df7-9c7c-932e7343bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamps = prepare_dataframes(\n",
    "    train_files,\n",
    "    train_movies,\n",
    "    lambda file: os.path.join(TIMESTAMPS_PATH, file), \n",
    "    prepare_csv\n",
    ")\n",
    "\n",
    "test_timestamps = prepare_dataframes(\n",
    "    test_files,\n",
    "    test_movies,\n",
    "    lambda file: os.path.join(TEST_TIMESTAMPS_PATH, file), \n",
    "    prepare_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2befcf-73ce-4bde-8e7f-febf7891d147",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc254cd7-894b-4afa-9f26-c31b3974db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = prepare_dataframes(\n",
    "    train_files,\n",
    "    train_movies,\n",
    "    lambda file: os.path.join(FEATURES_PATH, get_feature_file(file)), \n",
    "    prepare_csv\n",
    ")\n",
    "\n",
    "test_features = prepare_dataframes(\n",
    "    test_files,\n",
    "    test_movies,\n",
    "    lambda file: os.path.join(TEST_FEATURES_PATH, get_feature_file(file)), \n",
    "    prepare_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467b2d-3432-42a9-964c-226ac931c302",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b36a21f1-9d62-4a9f-a51f-c355a49a96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for idx, file in enumerate(train_files):\n",
    "    # print(feature_files[idx])\n",
    "    labels_path = os.path.join(LABELS_PATH, get_feature_file(file))\n",
    "    \n",
    "    df = pd.read_csv(labels_path, keep_default_na=False)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Unnamed: 0\": \"scene_id\",\n",
    "            \"0\": \"label\"\n",
    "        }, inplace=True\n",
    "    )\n",
    "    df[\"movie\"] = movies[idx]\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "train_labels = pd.concat(dfs, ignore_index=True)\n",
    "# print(train_labels.shape)\n",
    "# train_labels.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d9296-bf27-47ed-8a17-9aa1f7773a7d",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "794727e1-b58f-4d9f-ba31-2aab8901196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 12)\n",
      "(2470, 11)\n"
     ]
    }
   ],
   "source": [
    "train_merged = merge_dataframes(train_timestamps, train_features)\n",
    "# additionaly merge labels to train data\n",
    "train_full_data = pd.merge(train_merged, train_labels, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "print(train_full_data.shape)\n",
    "\n",
    "test_full_data = merge_dataframes(test_timestamps, test_features)\n",
    "print(test_full_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a819c-9244-4014-bb3d-0e3182cb63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>label</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>Finale</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>Finale</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>dallas buyers club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id        label               movie\n",
       "3724       220       Finale  dallas buyers club\n",
       "3725       221       Finale  dallas buyers club\n",
       "3726       224  Final Image  dallas buyers club\n",
       "3727       226  Final Image  dallas buyers club\n",
       "3728       227  Final Image  dallas buyers club"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfs = []\n",
    "# for idx, file in enumerate(files):\n",
    "#     # print(feature_files[idx])\n",
    "#     labels_path = os.path.join(LABELS_PATH, feature_files[idx])\n",
    "    \n",
    "#     df = pd.read_csv(labels_path, keep_default_na=False)\n",
    "#     df.rename(\n",
    "#         columns={\n",
    "#             \"Unnamed: 0\": \"scene_id\",\n",
    "#             \"0\": \"label\"\n",
    "#         }, inplace=True\n",
    "#     )\n",
    "#     df[\"movie\"] = movies[idx]\n",
    "    \n",
    "#     dfs.append(df)\n",
    "\n",
    "# labels = pd.concat(dfs, ignore_index=True)\n",
    "# print(labels.shape)\n",
    "# labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaced6b2-e619-4134-80ea-932c5a7eb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps_features = pd.merge(timestamps, features, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "# full_data = pd.merge(timestamps_features, labels, on=[\"scene_id\", \"movie\"], how=\"outer\")\n",
    "\n",
    "# print(full_data.shape)\n",
    "# full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fcb2f39-2263-4b87-9be2-f3a05dcaf462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>6499.655</td>\n",
       "      <td>6574.354333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>74.699333</td>\n",
       "      <td>16</td>\n",
       "      <td>4.668708</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>656.478716</td>\n",
       "      <td>1</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>6579.776333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>372.108700</td>\n",
       "      <td>0</td>\n",
       "      <td>Finale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>6589.161</td>\n",
       "      <td>6623.987333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>34.826333</td>\n",
       "      <td>6</td>\n",
       "      <td>5.804389</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>928.370357</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>6629.701</td>\n",
       "      <td>6682.462333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>52.761333</td>\n",
       "      <td>19</td>\n",
       "      <td>2.776912</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>1076.267498</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>6682.504</td>\n",
       "      <td>6688.176333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.672333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.418083</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>2085.459362</td>\n",
       "      <td>1</td>\n",
       "      <td>Final Image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start          end               movie      s_dur  n_shots  \\\n",
       "3724       220  6499.655  6574.354333  dallas buyers club  74.699333       16   \n",
       "3725       221  6574.396  6579.776333  dallas buyers club   5.380333        1   \n",
       "3726       224  6589.161  6623.987333  dallas buyers club  34.826333        6   \n",
       "3727       226  6629.701  6682.462333  dallas buyers club  52.761333       19   \n",
       "3728       227  6682.504  6688.176333  dallas buyers club   5.672333        4   \n",
       "\n",
       "      ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  is_prot_appear  \\\n",
       "3724      4.668708    0.960699   0.926278      656.478716               1   \n",
       "3725      5.380333    0.965066   0.936929      372.108700               0   \n",
       "3726      5.804389    0.978166   0.939033      928.370357               1   \n",
       "3727      2.776912    0.986900   0.944811     1076.267498               1   \n",
       "3728      1.418083    0.991266   0.952336     2085.459362               1   \n",
       "\n",
       "            label  \n",
       "3724       Finale  \n",
       "3725       Finale  \n",
       "3726  Final Image  \n",
       "3727  Final Image  \n",
       "3728  Final Image  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_data[\"end\"] = full_data[\"start\"] + full_data[\"s_dur\"]\n",
    "# full_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c61e3-fdb8-45bd-9d9e-f47fff1e28fb",
   "metadata": {},
   "source": [
    "## Ssubtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70dc66ea-b37c-47aa-87b7-94c0e4c754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b2751-a43c-4cf1-9b6b-6ea8e573fc1e",
   "metadata": {},
   "source": [
    "### Helper runctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6768479e-06be-4fff-935f-7424174598ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_movies = [\"the ugly truth\", \"the social network\", \"the girl with the dragon tattoo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "21b168cf-f6f1-429e-92ae-0f0f4e31033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_files_to_subtitles(files):\n",
    "    return [file.replace('.csv', '.srt') for file in files]\n",
    "\n",
    "def load_subtitles(paths, movies):\n",
    "    movie_subtitles = {}\n",
    "    for idx, movie_name in enumerate(movies):\n",
    "        # print(movie_name)\n",
    "        \n",
    "        if movie_name == \"pretty woman\":\n",
    "            with open(paths[idx], 'r', encoding='utf-16') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "        elif movie_name in problematic_movies:\n",
    "            with open(paths[idx], 'r', encoding='utf-8', errors='replace') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "        else:\n",
    "            with open(paths[idx], 'r', encoding='utf-8') as subtitle_file:\n",
    "                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n",
    "                \n",
    "    return movie_subtitles\n",
    "\n",
    "def associate_scenes_with_subtitles(full_data, movie_subtitles):\n",
    "    movies_scenes_subtitles = {}\n",
    "    last_processed_subtitle_idx = 0\n",
    "    missed_subtitles = 0\n",
    "\n",
    "    for scene_idx, scene_row in full_data.iterrows():\n",
    "        scene_start, scene_end = scene_row['start'], scene_row['end']\n",
    "        scene_id, movie_name = scene_row['scene_id'], scene_row['movie']\n",
    "        \n",
    "        # Create new dictionary for every movie\n",
    "        if movie_name not in movies_scenes_subtitles:\n",
    "            movies_scenes_subtitles[movie_name] = {}\n",
    "            last_processed_subtitle_idx = 0\n",
    "\n",
    "        # Craete new dictionary for every scene within movie\n",
    "        movies_scenes_subtitles[movie_name][scene_id] = []\n",
    "\n",
    "        current_movie_subtitles = movie_subtitles[movie_name]\n",
    "        for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n",
    "            sub = current_movie_subtitles[idx]\n",
    "            sub_start, sub_end = sub.start.total_seconds(), sub.end.total_seconds()\n",
    "\n",
    "            # Some subtitles start just before scene_start\n",
    "            if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n",
    "                # Add subtitle content to the dictionary for the current scene\n",
    "                movies_scenes_subtitles[movie_name][scene_id].append(sub.content)\n",
    "            elif scene_end < sub_end:\n",
    "                last_processed_subtitle_idx = idx\n",
    "                break\n",
    "            else:\n",
    "                missed_subtitles += 1\n",
    "\n",
    "    print(f\"Ignored subtitltes: {missed_subtitles}\")\n",
    "    return movies_scenes_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1d8d17c4-bf20-4b1a-9db5-c947a1397ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1fad981b-2541-4364-9015-244f7c173488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(movies_scenes_subtitles):\n",
    "    embeddings = {}\n",
    "    for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "        for scene_id, combined_text in scenes.items():\n",
    "            inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "            embeddings.setdefault(movie_name, {})[scene_id] = embedding\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb2a42-e9e0-4b51-8851-6f3c3989e397",
   "metadata": {},
   "source": [
    "### Get subtitle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7fe0cf7b-cb14-4eb1-a65d-376ce385faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_files = load_files(FEATURES_PATH)\n",
    "# remove australia because australia subtitles are in diffrent format than everything else\n",
    "train_features_files.remove('tt0455824_australia.csv')\n",
    "test_features_files = load_files(TEST_FEATURES_PATH)\n",
    "\n",
    "train_subtitles_files = convert_files_to_subtitles(train_features_files)\n",
    "train_subtitle_paths = [os.path.join(SUBTITLES_PATH, subtitle_file) for subtitle_file in train_subtitles_files]\n",
    "\n",
    "test_subtitles_files = convert_files_to_subtitles(test_features_files)\n",
    "test_subtitle_paths = [os.path.join(TEST_SUBTITLES_PATH, subtitle_file) for subtitle_file in test_subtitles_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49999294-c505-4b00-a2be-0f8a5c24ff3e",
   "metadata": {},
   "source": [
    "### Load subtitles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6c910f57-e1ec-4562-9f27-92e13cc52825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movie_subtitles = load_subtitles(train_subtitle_paths, train_movies)\n",
    "test_movie_subtitles = load_subtitles(test_subtitle_paths, test_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad00e5-ee25-4e9d-85de-44e39278862d",
   "metadata": {},
   "source": [
    "### Associate Scenes with subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9c1dd419-8d7d-4c19-9d8d-74f5588d0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored subtitltes: 3018\n",
      "Ignored subtitltes: 3165\n"
     ]
    }
   ],
   "source": [
    "train_movies_scenes_subtitles = associate_scenes_with_subtitles(train_full_data, train_movie_subtitles)\n",
    "test_movies_scenes_subtitles = associate_scenes_with_subtitles(test_full_data, test_movie_subtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0a6fe",
   "metadata": {},
   "source": [
    "## Subtitles cleaning and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d1034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "    for scene_id, subtitles in scenes.items():\n",
    "        cleaned_subtitles = []\n",
    "        for subtitle in subtitles:\n",
    "            # Remove new line characters\n",
    "            cleaned_subtitle = subtitle.replace('\\n', ' ').strip()\n",
    "            cleaned_subtitle = re.sub(r'<.*?>', '', cleaned_subtitle)\n",
    "            cleaned_subtitle = re.sub(r'♪', '', cleaned_subtitle)\n",
    "            cleaned_subtitles.append(cleaned_subtitle)\n",
    "        combined_text = \" \".join(cleaned_subtitles)\n",
    "        movies_scenes_subtitles[movie_name][scene_id] = combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48092566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Although I can't dismiss   The memory of her kiss   I guess he's not for me \""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_scenes_subtitles['four weddings and a funeral'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cafdd5",
   "metadata": {},
   "source": [
    "## Tokenize and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98486364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# embeddings = []\n",
    "# for movie_name, scenes in movies_scenes_subtitles.items():\n",
    "#     for scene_id, combined_text in scenes.items():\n",
    "#         inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}  # move tensors to GPU\n",
    "#         outputs = model(**inputs)\n",
    "#         embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().tolist() # move outputs to CPU\n",
    "#         movies_scenes_subtitles[movie_name][scene_id] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_scenes_subtitles['pretty woman'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e715b4",
   "metadata": {},
   "source": [
    "## Merge with Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5366b0d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>movie</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>218.718333</td>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>218.718333</td>\n",
       "      <td>6</td>\n",
       "      <td>36.453056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>You'd better take this along, Don. It's gonna ...</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>218.760</td>\n",
       "      <td>240.740333</td>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>21.980333</td>\n",
       "      <td>3</td>\n",
       "      <td>7.326778</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>Are you sure it's in the closet? I can't find ...</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>240.782</td>\n",
       "      <td>282.574333</td>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>41.792333</td>\n",
       "      <td>1</td>\n",
       "      <td>41.792333</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.039832</td>\n",
       "      <td>1256.344447</td>\n",
       "      <td>1</td>\n",
       "      <td>- Did you find it? - Oh, sure, sure. Here it i...</td>\n",
       "      <td>Set-Up</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>282.616</td>\n",
       "      <td>313.521333</td>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>30.905333</td>\n",
       "      <td>1</td>\n",
       "      <td>30.905333</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.046752</td>\n",
       "      <td>1256.344447</td>\n",
       "      <td>1</td>\n",
       "      <td>The new Thurber book with comical jokes and pi...</td>\n",
       "      <td>Set-Up</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>313.563</td>\n",
       "      <td>367.033333</td>\n",
       "      <td>the lost weekend</td>\n",
       "      <td>53.470333</td>\n",
       "      <td>4</td>\n",
       "      <td>13.367583</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.051871</td>\n",
       "      <td>1256.344447</td>\n",
       "      <td>1</td>\n",
       "      <td>Nobody? What are they playing? Brahms' 2nd Sym...</td>\n",
       "      <td>Theme Stated</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>220</td>\n",
       "      <td>6499.655</td>\n",
       "      <td>6574.354333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>74.699333</td>\n",
       "      <td>16</td>\n",
       "      <td>4.668708</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>656.478716</td>\n",
       "      <td>1</td>\n",
       "      <td>to be mentally healthy or physically healthy. ...</td>\n",
       "      <td>Finale</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>221</td>\n",
       "      <td>6574.396</td>\n",
       "      <td>6579.776333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.380333</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>372.108700</td>\n",
       "      <td>0</td>\n",
       "      <td>DAVID: We lost. (SIGHS)</td>\n",
       "      <td>Finale</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>224</td>\n",
       "      <td>6589.161</td>\n",
       "      <td>6623.987333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>34.826333</td>\n",
       "      <td>6</td>\n",
       "      <td>5.804389</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>928.370357</td>\n",
       "      <td>1</td>\n",
       "      <td>What?</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>226</td>\n",
       "      <td>6629.701</td>\n",
       "      <td>6682.462333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>52.761333</td>\n",
       "      <td>19</td>\n",
       "      <td>2.776912</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>1076.267498</td>\n",
       "      <td>1</td>\n",
       "      <td>MAN ON PA: Yes, indeed, the number one spectat...</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>227</td>\n",
       "      <td>6682.504</td>\n",
       "      <td>6688.176333</td>\n",
       "      <td>dallas buyers club</td>\n",
       "      <td>5.672333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.418083</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>2085.459362</td>\n",
       "      <td>1</td>\n",
       "      <td>It's bull ride time!</td>\n",
       "      <td>Final Image</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_id     start          end               movie       s_dur  \\\n",
       "0            0     0.000   218.718333    the lost weekend  218.718333   \n",
       "1            1   218.760   240.740333    the lost weekend   21.980333   \n",
       "2            2   240.782   282.574333    the lost weekend   41.792333   \n",
       "3            3   282.616   313.521333    the lost weekend   30.905333   \n",
       "4            4   313.563   367.033333    the lost weekend   53.470333   \n",
       "...        ...       ...          ...                 ...         ...   \n",
       "3724       220  6499.655  6574.354333  dallas buyers club   74.699333   \n",
       "3725       221  6574.396  6579.776333  dallas buyers club    5.380333   \n",
       "3726       224  6589.161  6623.987333  dallas buyers club   34.826333   \n",
       "3727       226  6629.701  6682.462333  dallas buyers club   52.761333   \n",
       "3728       227  6682.504  6688.176333  dallas buyers club    5.672333   \n",
       "\n",
       "      n_shots  ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  \\\n",
       "0           6     36.453056    0.000000   0.000000     1295.579078   \n",
       "1           3      7.326778    0.008403   0.036189     1295.579078   \n",
       "2           1     41.792333    0.016807   0.039832     1256.344447   \n",
       "3           1     30.905333    0.025210   0.046752     1256.344447   \n",
       "4           4     13.367583    0.033613   0.051871     1256.344447   \n",
       "...       ...           ...         ...        ...             ...   \n",
       "3724       16      4.668708    0.960699   0.926278      656.478716   \n",
       "3725        1      5.380333    0.965066   0.936929      372.108700   \n",
       "3726        6      5.804389    0.978166   0.939033      928.370357   \n",
       "3727       19      2.776912    0.986900   0.944811     1076.267498   \n",
       "3728        4      1.418083    0.991266   0.952336     2085.459362   \n",
       "\n",
       "      is_prot_appear                                               text  \\\n",
       "0                  1  You'd better take this along, Don. It's gonna ...   \n",
       "1                  1  Are you sure it's in the closet? I can't find ...   \n",
       "2                  1  - Did you find it? - Oh, sure, sure. Here it i...   \n",
       "3                  1  The new Thurber book with comical jokes and pi...   \n",
       "4                  1  Nobody? What are they playing? Brahms' 2nd Sym...   \n",
       "...              ...                                                ...   \n",
       "3724               1  to be mentally healthy or physically healthy. ...   \n",
       "3725               0                            DAVID: We lost. (SIGHS)   \n",
       "3726               1                                              What?   \n",
       "3727               1  MAN ON PA: Yes, indeed, the number one spectat...   \n",
       "3728               1                               It's bull ride time!   \n",
       "\n",
       "              label  encoded_label  \n",
       "0     Opening Image             13  \n",
       "1     Opening Image             13  \n",
       "2            Set-Up             14  \n",
       "3            Set-Up             14  \n",
       "4      Theme Stated             15  \n",
       "...             ...            ...  \n",
       "3724         Finale              9  \n",
       "3725         Finale              9  \n",
       "3726    Final Image              8  \n",
       "3727    Final Image              8  \n",
       "3728    Final Image              8  \n",
       "\n",
       "[3729 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings = []\n",
    "# for index, row in full_data.iterrows():\n",
    "#     movie_name = row['movie']\n",
    "#     scene_id = row['scene_id']\n",
    "    \n",
    "#     embedding = movies_scenes_subtitles.get(movie_name, {}).get(scene_id, None)\n",
    "    \n",
    "#     embeddings.append(embedding)\n",
    "\n",
    "# full_data.insert(full_data.columns.get_loc('label'), 'embedding', embeddings)\n",
    "# full_data.tail()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = []\n",
    "for movie, scenes in movies_scenes_subtitles.items():\n",
    "    for scene_number, text in scenes.items():\n",
    "        data.append({\"movie\": movie, \"scene\": scene_number, \"text\": text})\n",
    "scenes_df = pd.DataFrame(data)\n",
    "\n",
    "full_data.insert(full_data.columns.get_loc('label'), 'text', scenes_df['text'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "full_data['encoded_label'] = label_encoder.fit_transform(full_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919f712-0189-4474-a50f-88d5882f48a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a0398-5819-43ff-8444-cdbb8f2e18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_scenes_embeddings = calculate_embeddings(train_movies_scenes_subtitles)\n",
    "\n",
    "train_embeddings = []\n",
    "for index, row in train_full_data.iterrows():\n",
    "    movie_name, scene_id = row['movie'], row['scene_id']\n",
    "    embedding = train_movies_scenes_embeddings.get(movie_name, {}).get(scene_id, None)\n",
    "    train_embeddings.append(embedding)\n",
    "\n",
    "test_full_data.insert(test_full_data.columns.get_loc('label'), 'embedding', train_embeddings)\n",
    "print(test_full_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ec6d1-e4db-4336-ac4b-bc66fb77511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies_scenes_embeddings = calculate_embeddings(test_movies_scenes_subtitles)\n",
    "\n",
    "test_embeddings = []\n",
    "for index, row in test_full_data.iterrows():\n",
    "    movie_name, scene_id = row['movie'], row['scene_id']\n",
    "    embedding = test_movies_scenes_embeddings.get(movie_name, {}).get(scene_id, None)\n",
    "    test_embeddings.append(embedding)\n",
    "\n",
    "test_full_data.insert(test_full_data.columns.get_loc('label'), 'embedding', test_embeddings)\n",
    "print(test_full_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3e098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334d013",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed7adb",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# full_data_clean = full_data.dropna()\n",
    "\n",
    "# embeddings = np.array(full_data_clean['embedding'].tolist())\n",
    "\n",
    "# X = full_data_clean[['s_dur', 'n_shots', 'ava_shot_dur', 'rel_id_loc', 'rel_t_loc', 'ava_char_score', 'is_prot_appear']]\n",
    "# X = np.hstack((X, embeddings))\n",
    "# y = full_data_clean['label']\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': [210, 240, 200, 225, 250],\n",
    "#     'min_samples_split': [15, 25, 35],\n",
    "#     'min_samples_leaf': [10, 15, 20],\n",
    "#     'max_depth': [10, 15, 20, 25, 30, 50]\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(RandomForestClassifier(random_state=23), param_distributions=param_dist, n_iter=10, cv=5, random_state=23, n_jobs=-1)\n",
    "# random_search.fit(X, y)\n",
    "\n",
    "# print(\"Best parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e338f7",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(random_state=23, n_estimators=200, min_samples_split=15, min_samples_leaf=20, max_depth=15)\n",
    "# model.fit(X, y)\n",
    "# y_pred = model.predict(X)\n",
    "# scores = cross_val_score(model, X, y, cv=5)\n",
    "# print(f\"Mean Accuracy from cross-validation: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff470f4-0400-4ec3-a8bc-aac7c47e08be",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e086559-82e7-44a9-a159-970d9dbd8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# _, levels = pd.factorize(full_data_clean['label'])\n",
    "# print(classification_report(y,y_pred,target_names=levels))\n",
    "\n",
    "# accuracy = accuracy_score(y, y_pred)\n",
    "# print()\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fc580-c101-41e6-b409-8fdf5003f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model', 'X', and 'y' are already defined\n",
    "# predicted = cross_val_predict(model, X, y, cv=5)\n",
    "# conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eff19d-1730-4609-afd1-e5ddc12c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12,10))\n",
    "# sns.heatmap(conf_matrix, fmt='g', ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a274c22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b280aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Studia\\Sem2-mgr\\ZED\\story-beats\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036b0dc",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a9229cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_data.drop(columns=['movie', 'encoded_label'])\n",
    "y = full_data['encoded_label']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, random_state=23, test_size=0.3, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, random_state=23, test_size=0.5, stratify=y_temp)\n",
    "\n",
    "train_texts = X_train['text']\n",
    "val_texts = X_val['text']\n",
    "test_texts = X_test['text']\n",
    "\n",
    "train_labels = y_train\n",
    "val_labels = y_val\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9d03f",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba43e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def encode_texts(texts, labels):\n",
    "    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(labels)\n",
    "    return encodings, labels\n",
    "\n",
    "train_encodings, train_labels = encode_texts(train_texts, train_labels.values)\n",
    "val_encodings, val_labels = encode_texts(val_texts, val_labels.values)\n",
    "test_encodings, test_labels = encode_texts(test_texts, test_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e5fbe",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e24a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  1,  9,  ...,  1,  9,  9], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "507ffa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], \n",
    "                              train_encodings['attention_mask'], \n",
    "                              train_labels)\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], \n",
    "                            val_encodings['attention_mask'], \n",
    "                            val_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], \n",
    "                             test_encodings['attention_mask'], \n",
    "                             test_labels)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b89e0",
   "metadata": {},
   "source": [
    "### Trening and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bf9a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\User\\Desktop\\Studia\\Sem2-mgr\\ZED\\story-beats\\venv\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 - Loss: 2.4764768867361235\n",
      "Epoch 1/12 - Validation Accuracy: 0.1625\n",
      "Epoch 2/12 - Loss: 2.446542373842704\n",
      "Epoch 2/12 - Validation Accuracy: 0.1529761904761905\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_encoder.classes_))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "def calculate_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Trening Model\n",
    "epochs = 12\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        b_labels = b_labels.long()\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Validation Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc500a76",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6672e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_test_accuracy = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_test_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "avg_test_accuracy = total_test_accuracy / len(test_loader)\n",
    "print(f'Test Accuracy: {avg_test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49408d5e",
   "metadata": {},
   "source": [
    "## Prepare testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f9776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9947f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
