{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7409175,"sourceType":"datasetVersion","datasetId":4309319},{"sourceId":7487389,"sourceType":"datasetVersion","datasetId":4359090}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports and global variables","metadata":{}},{"cell_type":"code","source":"# !du -h --max-depth=1 /kaggle/working\n# !rm -rf /kaggle/working\n# !rm -rf /kaggle/working/results_fold*\n# !ls  /kaggle/working/results","metadata":{"execution":{"iopub.status.busy":"2024-01-26T16:56:30.204331Z","iopub.execute_input":"2024-01-26T16:56:30.205302Z","iopub.status.idle":"2024-01-26T16:56:32.638367Z","shell.execute_reply.started":"2024-01-26T16:56:30.205267Z","shell.execute_reply":"2024-01-26T16:56:32.637000Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !pip install srt --target=/kaggle/working/\n# !pip install srt\n\n# !pip install numpy==1.18\n# !pip install scipy==1.1.0\n# !pip install scikit-learn==0.21.3\n\n# !pip install datasets --upgrade --target=/kaggle/working/\n# !pip install datasets --upgrade\n\n# !pip install evaluate --target=/kaggle/working/\n# !pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-01-18T16:21:19.485167Z","iopub.execute_input":"2024-01-18T16:21:19.485416Z","iopub.status.idle":"2024-01-18T16:21:19.495261Z","shell.execute_reply.started":"2024-01-18T16:21:19.485395Z","shell.execute_reply":"2024-01-18T16:21:19.494550Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import datasets\nprint(datasets.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:04.691371Z","iopub.execute_input":"2024-01-26T18:04:04.691629Z","iopub.status.idle":"2024-01-26T18:04:04.703364Z","shell.execute_reply.started":"2024-01-26T18:04:04.691606Z","shell.execute_reply":"2024-01-26T18:04:04.702505Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:04.704667Z","iopub.execute_input":"2024-01-26T18:04:04.704921Z","iopub.status.idle":"2024-01-26T18:04:04.714429Z","shell.execute_reply.started":"2024-01-26T18:04:04.704899Z","shell.execute_reply":"2024-01-26T18:04:04.713711Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"STORY_BEATS_PATH = '/kaggle/input/story-beats-2'\n\nTIMESTAMPS_PATH = f\"{STORY_BEATS_PATH}/train/train/scene_timestamps\"\nFEATURES_PATH = f\"{STORY_BEATS_PATH}/train/train/features\"\nLABELS_PATH = f\"{STORY_BEATS_PATH}/train/train/labels\"\nSUBTITLES_PATH = f\"{STORY_BEATS_PATH}/train/train/subtitles\"\n\nTEST_TIMESTAMPS_PATH = f\"{STORY_BEATS_PATH}/test/test/scene_timestamps\"\nTEST_FEATURES_PATH = f\"{STORY_BEATS_PATH}/test/test/features\"\nTEST_SUBTITLES_PATH = f\"{STORY_BEATS_PATH}/test/test/subtitles\"","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:05.476073Z","iopub.execute_input":"2024-01-26T18:04:05.476452Z","iopub.status.idle":"2024-01-26T18:04:05.481671Z","shell.execute_reply.started":"2024-01-26T18:04:05.476423Z","shell.execute_reply":"2024-01-26T18:04:05.480778Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Check GPU available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:07.053681Z","iopub.execute_input":"2024-01-26T18:04:07.055675Z","iopub.status.idle":"2024-01-26T18:04:07.098700Z","shell.execute_reply.started":"2024-01-26T18:04:07.055446Z","shell.execute_reply":"2024-01-26T18:04:07.097117Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"code","source":"def load_files(path):\n    if os.path.exists(path):\n        files = os.listdir(path)\n        return sorted(files)\n    else:\n        print(\"PATH DOES NOT EXIST!\")\n        return []","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:09.028210Z","iopub.execute_input":"2024-01-26T18:04:09.029053Z","iopub.status.idle":"2024-01-26T18:04:09.033670Z","shell.execute_reply.started":"2024-01-26T18:04:09.029019Z","shell.execute_reply":"2024-01-26T18:04:09.032720Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_movie_name(file):\n    return file[10:-15]\n\ndef get_movie_id(file):\n    return file[:9]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:09.217998Z","iopub.execute_input":"2024-01-26T18:04:09.218247Z","iopub.status.idle":"2024-01-26T18:04:09.222651Z","shell.execute_reply.started":"2024-01-26T18:04:09.218225Z","shell.execute_reply":"2024-01-26T18:04:09.221777Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_feature_file(file):\n    return file.replace(\"_timestamps\", \"\")","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:09.386760Z","iopub.execute_input":"2024-01-26T18:04:09.387020Z","iopub.status.idle":"2024-01-26T18:04:09.391117Z","shell.execute_reply.started":"2024-01-26T18:04:09.386998Z","shell.execute_reply":"2024-01-26T18:04:09.390258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def prepare_csv(path, movie_name):\n    df = pd.read_csv(path)\n    df.rename(columns={\"Unnamed: 0\": \"scene_id\"}, inplace=True)\n    df[\"movie\"] = movie_name\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:09.588134Z","iopub.execute_input":"2024-01-26T18:04:09.588943Z","iopub.status.idle":"2024-01-26T18:04:09.593677Z","shell.execute_reply.started":"2024-01-26T18:04:09.588906Z","shell.execute_reply":"2024-01-26T18:04:09.592794Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def extract_movie_info(files):\n    movie_ids, movies = [], []\n    for file in files:\n        movie_name = get_movie_name(file)\n        movie_id = get_movie_id(file)\n        movie_ids.append(movie_id)\n        movies.append(movie_name)\n    return movie_ids, movies\n\ndef prepare_dataframes(files, movies, path_func, data_func):\n    dfs = []\n    for idx, file in enumerate(files):\n        path = path_func(file)\n        df = data_func(path, movies[idx])\n        dfs.append(df)\n    return pd.concat(dfs, ignore_index=True)\n\ndef merge_dataframes(df1, df2):\n    test_full_data = pd.merge(df1, df2, on=[\"scene_id\", \"movie\"])\n    test_full_data[\"end\"] = test_full_data[\"start\"] + test_full_data[\"s_dur\"]\n    return test_full_data","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:09.760871Z","iopub.execute_input":"2024-01-26T18:04:09.761118Z","iopub.status.idle":"2024-01-26T18:04:09.767923Z","shell.execute_reply.started":"2024-01-26T18:04:09.761097Z","shell.execute_reply":"2024-01-26T18:04:09.767109Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Convert ass to srt","metadata":{}},{"cell_type":"markdown","source":"### Files","metadata":{}},{"cell_type":"code","source":"train_files = load_files(TIMESTAMPS_PATH)\n# remove australia because australia subtitles are in diffrent format than everything else\n# train_files.remove(\"tt0455824_australia_timestamps.csv\")\n\ntest_files = load_files(TEST_TIMESTAMPS_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:10.328820Z","iopub.execute_input":"2024-01-26T18:04:10.329530Z","iopub.status.idle":"2024-01-26T18:04:10.356529Z","shell.execute_reply.started":"2024-01-26T18:04:10.329494Z","shell.execute_reply":"2024-01-26T18:04:10.355774Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Movies","metadata":{}},{"cell_type":"code","source":"train_movies_ids, train_movies = extract_movie_info(train_files)\ntest_movies_ids, test_movies = extract_movie_info(test_files)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:10.698154Z","iopub.execute_input":"2024-01-26T18:04:10.698458Z","iopub.status.idle":"2024-01-26T18:04:10.702727Z","shell.execute_reply.started":"2024-01-26T18:04:10.698432Z","shell.execute_reply":"2024-01-26T18:04:10.701814Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Timestamps","metadata":{}},{"cell_type":"code","source":"train_timestamps = prepare_dataframes(\n    train_files,\n    train_movies,\n    lambda file: os.path.join(TIMESTAMPS_PATH, file), \n    prepare_csv\n)\n\ntest_timestamps = prepare_dataframes(\n    test_files,\n    test_movies,\n    lambda file: os.path.join(TEST_TIMESTAMPS_PATH, file), \n    prepare_csv\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:11.055853Z","iopub.execute_input":"2024-01-26T18:04:11.056210Z","iopub.status.idle":"2024-01-26T18:04:11.300584Z","shell.execute_reply.started":"2024-01-26T18:04:11.056182Z","shell.execute_reply":"2024-01-26T18:04:11.299650Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Features","metadata":{}},{"cell_type":"code","source":"train_features = prepare_dataframes(\n    train_files,\n    train_movies,\n    lambda file: os.path.join(FEATURES_PATH, get_feature_file(file)), \n    prepare_csv\n)\n\ntest_features = prepare_dataframes(\n    test_files,\n    test_movies,\n    lambda file: os.path.join(TEST_FEATURES_PATH, get_feature_file(file)), \n    prepare_csv\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:11.440108Z","iopub.execute_input":"2024-01-26T18:04:11.440441Z","iopub.status.idle":"2024-01-26T18:04:11.791035Z","shell.execute_reply.started":"2024-01-26T18:04:11.440414Z","shell.execute_reply":"2024-01-26T18:04:11.790072Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Labels","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor idx, file in enumerate(train_files):\n    # print(feature_files[idx])\n    labels_path = os.path.join(LABELS_PATH, get_feature_file(file))\n    \n    df = pd.read_csv(labels_path, keep_default_na=False)\n    df.rename(\n        columns={\n            \"Unnamed: 0\": \"scene_id\",\n            \"0\": \"label\"\n        }, inplace=True\n    )\n    df[\"movie\"] = train_movies[idx]\n    \n    dfs.append(df)\n\ntrain_labels = pd.concat(dfs, ignore_index=True)\n# print(train_labels.shape)\n# train_labels.tail()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:11.821858Z","iopub.execute_input":"2024-01-26T18:04:11.822142Z","iopub.status.idle":"2024-01-26T18:04:12.006325Z","shell.execute_reply.started":"2024-01-26T18:04:11.822118Z","shell.execute_reply":"2024-01-26T18:04:12.005573Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Merge dataframes","metadata":{}},{"cell_type":"code","source":"train_merged = merge_dataframes(train_timestamps, train_features)\n# additionaly merge labels to train data\ntrain_full_data = pd.merge(train_merged, train_labels, on=[\"scene_id\", \"movie\"], how=\"outer\")\nprint(train_full_data.shape)\n\ntest_full_data = merge_dataframes(test_timestamps, test_features)\nprint(test_full_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:12.218824Z","iopub.execute_input":"2024-01-26T18:04:12.219188Z","iopub.status.idle":"2024-01-26T18:04:12.240632Z","shell.execute_reply.started":"2024-01-26T18:04:12.219157Z","shell.execute_reply":"2024-01-26T18:04:12.239518Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(3978, 12)\n(2470, 11)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Join Scenes with subtitles","metadata":{}},{"cell_type":"code","source":"import srt","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:12.600695Z","iopub.execute_input":"2024-01-26T18:04:12.601046Z","iopub.status.idle":"2024-01-26T18:04:12.614624Z","shell.execute_reply.started":"2024-01-26T18:04:12.601019Z","shell.execute_reply":"2024-01-26T18:04:12.613837Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Helper runctions","metadata":{}},{"cell_type":"code","source":"train_movie_scenes_count = train_full_data.groupby('movie').count()['scene_id']\n# print(train_movie_scenes_count)\ntest_movie_scenes_count = test_full_data.groupby('movie').count()['scene_id']","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:12.984354Z","iopub.execute_input":"2024-01-26T18:04:12.984715Z","iopub.status.idle":"2024-01-26T18:04:12.994463Z","shell.execute_reply.started":"2024-01-26T18:04:12.984689Z","shell.execute_reply":"2024-01-26T18:04:12.993563Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_full_data","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:13.172815Z","iopub.execute_input":"2024-01-26T18:04:13.173161Z","iopub.status.idle":"2024-01-26T18:04:13.203012Z","shell.execute_reply.started":"2024-01-26T18:04:13.173132Z","shell.execute_reply":"2024-01-26T18:04:13.202029Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"      scene_id     start          end               movie       s_dur  \\\n0            0     0.000   218.718333    the lost weekend  218.718333   \n1            1   218.760   240.740333    the lost weekend   21.980333   \n2            2   240.782   282.574333    the lost weekend   41.792333   \n3            3   282.616   313.521333    the lost weekend   30.905333   \n4            4   313.563   367.033333    the lost weekend   53.470333   \n...        ...       ...          ...                 ...         ...   \n3973       220  6499.655  6574.354333  dallas buyers club   74.699333   \n3974       221  6574.396  6579.776333  dallas buyers club    5.380333   \n3975       224  6589.161  6623.987333  dallas buyers club   34.826333   \n3976       226  6629.701  6682.462333  dallas buyers club   52.761333   \n3977       227  6682.504  6688.176333  dallas buyers club    5.672333   \n\n      n_shots  ava_shot_dur  rel_id_loc  rel_t_loc  ava_char_score  \\\n0           6     36.453056    0.000000   0.000000     1295.579078   \n1           3      7.326778    0.008403   0.036189     1295.579078   \n2           1     41.792333    0.016807   0.039832     1256.344447   \n3           1     30.905333    0.025210   0.046752     1256.344447   \n4           4     13.367583    0.033613   0.051871     1256.344447   \n...       ...           ...         ...        ...             ...   \n3973       16      4.668708    0.960699   0.926278      656.478716   \n3974        1      5.380333    0.965066   0.936929      372.108700   \n3975        6      5.804389    0.978166   0.939033      928.370357   \n3976       19      2.776912    0.986900   0.944811     1076.267498   \n3977        4      1.418083    0.991266   0.952336     2085.459362   \n\n      is_prot_appear          label  \n0                  1  Opening Image  \n1                  1  Opening Image  \n2                  1         Set-Up  \n3                  1         Set-Up  \n4                  1   Theme Stated  \n...              ...            ...  \n3973               1         Finale  \n3974               0         Finale  \n3975               1    Final Image  \n3976               1    Final Image  \n3977               1    Final Image  \n\n[3978 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scene_id</th>\n      <th>start</th>\n      <th>end</th>\n      <th>movie</th>\n      <th>s_dur</th>\n      <th>n_shots</th>\n      <th>ava_shot_dur</th>\n      <th>rel_id_loc</th>\n      <th>rel_t_loc</th>\n      <th>ava_char_score</th>\n      <th>is_prot_appear</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.000</td>\n      <td>218.718333</td>\n      <td>the lost weekend</td>\n      <td>218.718333</td>\n      <td>6</td>\n      <td>36.453056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1295.579078</td>\n      <td>1</td>\n      <td>Opening Image</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>218.760</td>\n      <td>240.740333</td>\n      <td>the lost weekend</td>\n      <td>21.980333</td>\n      <td>3</td>\n      <td>7.326778</td>\n      <td>0.008403</td>\n      <td>0.036189</td>\n      <td>1295.579078</td>\n      <td>1</td>\n      <td>Opening Image</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>240.782</td>\n      <td>282.574333</td>\n      <td>the lost weekend</td>\n      <td>41.792333</td>\n      <td>1</td>\n      <td>41.792333</td>\n      <td>0.016807</td>\n      <td>0.039832</td>\n      <td>1256.344447</td>\n      <td>1</td>\n      <td>Set-Up</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>282.616</td>\n      <td>313.521333</td>\n      <td>the lost weekend</td>\n      <td>30.905333</td>\n      <td>1</td>\n      <td>30.905333</td>\n      <td>0.025210</td>\n      <td>0.046752</td>\n      <td>1256.344447</td>\n      <td>1</td>\n      <td>Set-Up</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>313.563</td>\n      <td>367.033333</td>\n      <td>the lost weekend</td>\n      <td>53.470333</td>\n      <td>4</td>\n      <td>13.367583</td>\n      <td>0.033613</td>\n      <td>0.051871</td>\n      <td>1256.344447</td>\n      <td>1</td>\n      <td>Theme Stated</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3973</th>\n      <td>220</td>\n      <td>6499.655</td>\n      <td>6574.354333</td>\n      <td>dallas buyers club</td>\n      <td>74.699333</td>\n      <td>16</td>\n      <td>4.668708</td>\n      <td>0.960699</td>\n      <td>0.926278</td>\n      <td>656.478716</td>\n      <td>1</td>\n      <td>Finale</td>\n    </tr>\n    <tr>\n      <th>3974</th>\n      <td>221</td>\n      <td>6574.396</td>\n      <td>6579.776333</td>\n      <td>dallas buyers club</td>\n      <td>5.380333</td>\n      <td>1</td>\n      <td>5.380333</td>\n      <td>0.965066</td>\n      <td>0.936929</td>\n      <td>372.108700</td>\n      <td>0</td>\n      <td>Finale</td>\n    </tr>\n    <tr>\n      <th>3975</th>\n      <td>224</td>\n      <td>6589.161</td>\n      <td>6623.987333</td>\n      <td>dallas buyers club</td>\n      <td>34.826333</td>\n      <td>6</td>\n      <td>5.804389</td>\n      <td>0.978166</td>\n      <td>0.939033</td>\n      <td>928.370357</td>\n      <td>1</td>\n      <td>Final Image</td>\n    </tr>\n    <tr>\n      <th>3976</th>\n      <td>226</td>\n      <td>6629.701</td>\n      <td>6682.462333</td>\n      <td>dallas buyers club</td>\n      <td>52.761333</td>\n      <td>19</td>\n      <td>2.776912</td>\n      <td>0.986900</td>\n      <td>0.944811</td>\n      <td>1076.267498</td>\n      <td>1</td>\n      <td>Final Image</td>\n    </tr>\n    <tr>\n      <th>3977</th>\n      <td>227</td>\n      <td>6682.504</td>\n      <td>6688.176333</td>\n      <td>dallas buyers club</td>\n      <td>5.672333</td>\n      <td>4</td>\n      <td>1.418083</td>\n      <td>0.991266</td>\n      <td>0.952336</td>\n      <td>2085.459362</td>\n      <td>1</td>\n      <td>Final Image</td>\n    </tr>\n  </tbody>\n</table>\n<p>3978 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"problematic_movies = [\"the ugly truth\", \"the social network\", \"the girl with the dragon tattoo\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:13.367521Z","iopub.execute_input":"2024-01-26T18:04:13.368318Z","iopub.status.idle":"2024-01-26T18:04:13.372248Z","shell.execute_reply.started":"2024-01-26T18:04:13.368270Z","shell.execute_reply":"2024-01-26T18:04:13.371441Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def convert_files_to_subtitles(files):\n    return [file.replace('.csv', '.srt') for file in files]\n\ndef load_subtitles(paths, movies):\n    movie_subtitles = {}\n    for idx, movie_name in enumerate(movies):\n#         print(movie_name)\n        if movie_name == \"pretty woman\":\n            with open(paths[idx], 'r', encoding='utf-16') as subtitle_file:\n                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n        elif movie_name in problematic_movies:\n            with open(paths[idx], 'r', encoding='utf-8', errors='replace') as subtitle_file:\n                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n        else:\n            with open(paths[idx], 'r', encoding='utf-8') as subtitle_file:\n                movie_subtitles[movie_name] = list(srt.parse(subtitle_file.read()))\n                \n    return movie_subtitles\n\ndef associate_scenes_with_subtitles(full_data, movie_subtitles):\n    movies_scenes_subtitles = {}\n    additional_data = []\n    last_processed_subtitle_idx = 0\n    missed_subtitles = 0\n\n    for scene_idx, scene_row in full_data.iterrows():\n        scene_start, scene_end = scene_row['start'], scene_row['end']\n        scene_id, movie_name = scene_row['scene_id'], scene_row['movie']\n        \n        # Create new dictionary for every movie\n        if movie_name not in movies_scenes_subtitles:\n            movies_scenes_subtitles[movie_name] = {}\n            last_processed_subtitle_idx = 0\n\n        # Craete new dictionary for every scene within movie\n        movies_scenes_subtitles[movie_name][scene_id] = []\n\n        current_movie_subtitles = movie_subtitles[movie_name]\n        sentence_count = 0\n        for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n            sub = current_movie_subtitles[idx]\n            sub_start, sub_end = sub.start.total_seconds(), sub.end.total_seconds()\n\n            # Some subtitles start just before scene_start\n            if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n                # Add subtitle content to the dictionary for the current scene\n                movies_scenes_subtitles[movie_name][scene_id].append(sub.content)\n                sentence_count += sub.content.count('.') + sub.content.count('!') + sub.content.count('?')\n            elif scene_end < sub_end:\n                last_processed_subtitle_idx = idx\n                break\n            else:\n                missed_subtitles += 1\n        \n        additional_data.append({\n            'movie': movie_name,\n            'scene_id': scene_id,\n            'sentence_count': sentence_count,\n        })\n\n    print(f\"Ignored subtitltes: {missed_subtitles}\")\n    additional_df = pd.DataFrame(additional_data)\n    return movies_scenes_subtitles, additional_df","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:15.122860Z","iopub.execute_input":"2024-01-26T18:04:15.123768Z","iopub.status.idle":"2024-01-26T18:04:15.137198Z","shell.execute_reply.started":"2024-01-26T18:04:15.123732Z","shell.execute_reply":"2024-01-26T18:04:15.136267Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def format_data(name, data):\n    formatted_data = \"{:.0f}\".format(data)\n    # print(f\"{name}{formatted_data}\")\n    return name + formatted_data\n\n\ndef map_scene_location_to_category(x):\n    scene_mapping = {\n        (0, 1): \"Opening\",\n        (2, 15): \"Setup\",\n        (16, 19): \"Debate\",\n        (20, 49): \"Story\",\n        (50, 75): \"BadGuys\",\n        (76, 89): \"Ending\",\n        (90, 99): \"Finale\",\n        (99, float('inf')): \"FinalImage\"\n    }\n\n    for percentage_range, category in scene_mapping.items():\n        if percentage_range[0] <= x <= percentage_range[1]:\n            return category\n\n    return \"InvalidValue\"\n\n\ndef associate_scenes_with_subtitles_extra_info(full_data, movie_subtitles, movie_scenes_count):\n    movies_scenes_subtitles = {}\n    last_processed_subtitle_idx = 0\n    missed_subtitles = 0\n\n    for scene_idx, scene_row in full_data.iterrows():\n        scene_start, scene_end = scene_row['start'], scene_row['end']\n        scene_id, movie_name = scene_row['scene_id'], scene_row['movie']\n        scene_location, time_location = scene_row['rel_id_loc'], scene_row['rel_t_loc'] \t\n        prot_appear = scene_row['is_prot_appear']\n        scene_count = movie_scenes_count[movie_name]\n\n        movie_name_without_spaces = movie_name.replace(\" \", \"\")\n        category = map_scene_location_to_category(int(scene_location * 100))\n        \n        scene_location_result = format_data(\"SceneLocation\", scene_location * 100)\n        time_location_result = format_data(\"TimeLocation\", time_location * 100)\n        category_result = f\"category{category}\"\n        movie_name_result = f\"MovieName{movie_name_without_spaces}\"\n        scene_start_result = format_data(\"SceneStart\", scene_start)\n        scene_end_result = format_data(\"SceneEnd\", scene_end)\n        prot_appear_result = format_data(\"ProtAppear\", prot_appear)\n        scene_count_result = format_data(\"SceneCount\", scene_count)\n        \n        # Create new dictionary for every movie\n        if movie_name not in movies_scenes_subtitles:\n            movies_scenes_subtitles[movie_name] = {}\n            last_processed_subtitle_idx = 0\n\n        # Craete new dictionary for every scene within movie\n        movies_scenes_subtitles[movie_name][scene_id] = []\n        movies_scenes_subtitles[movie_name][scene_id].append(scene_location_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(time_location_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(category_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(movie_name_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(scene_start_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(scene_end_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(prot_appear_result)\n        movies_scenes_subtitles[movie_name][scene_id].append(scene_count_result)\n\n        current_movie_subtitles = movie_subtitles[movie_name]\n        for idx in range(last_processed_subtitle_idx, len(current_movie_subtitles)):\n            sub = current_movie_subtitles[idx]\n            sub_start, sub_end = sub.start.total_seconds(), sub.end.total_seconds()\n\n            # Some subtitles start just before scene_start\n            if scene_start <= (sub_start + 0.05) and scene_end >= sub_end:\n                # Add subtitle content to the dictionary for the current scene\n                movies_scenes_subtitles[movie_name][scene_id].append(sub.content)\n            elif scene_end < sub_end:\n                last_processed_subtitle_idx = idx\n                break\n            else:\n                missed_subtitles += 1\n        \n    print(f\"Ignored subtitltes: {missed_subtitles}\")\n    return movies_scenes_subtitles","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:15.370552Z","iopub.execute_input":"2024-01-26T18:04:15.371251Z","iopub.status.idle":"2024-01-26T18:04:15.387411Z","shell.execute_reply.started":"2024-01-26T18:04:15.371222Z","shell.execute_reply":"2024-01-26T18:04:15.386515Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Get subtitle files","metadata":{}},{"cell_type":"code","source":"train_features_files = load_files(FEATURES_PATH)\n# remove australia because australia subtitles are in diffrent format than everything else\n# train_features_files.remove('tt0455824_australia.csv')\ntest_features_files = load_files(TEST_FEATURES_PATH)\n\ntrain_subtitles_files = convert_files_to_subtitles(train_features_files)\ntrain_subtitle_paths = [os.path.join(SUBTITLES_PATH, subtitle_file) for subtitle_file in train_subtitles_files]\n\ntest_subtitles_files = convert_files_to_subtitles(test_features_files)\ntest_subtitle_paths = [os.path.join(TEST_SUBTITLES_PATH, subtitle_file) for subtitle_file in test_subtitles_files]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:17.199318Z","iopub.execute_input":"2024-01-26T18:04:17.200110Z","iopub.status.idle":"2024-01-26T18:04:17.216143Z","shell.execute_reply.started":"2024-01-26T18:04:17.200079Z","shell.execute_reply":"2024-01-26T18:04:17.215287Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Load subtitles ","metadata":{}},{"cell_type":"code","source":"train_movie_subtitles = load_subtitles(train_subtitle_paths, train_movies)\ntest_movie_subtitles = load_subtitles(test_subtitle_paths, test_movies)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:19.304903Z","iopub.execute_input":"2024-01-26T18:04:19.305625Z","iopub.status.idle":"2024-01-26T18:04:21.505494Z","shell.execute_reply.started":"2024-01-26T18:04:19.305592Z","shell.execute_reply":"2024-01-26T18:04:21.504579Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Associate Scenes with subtitles","metadata":{}},{"cell_type":"code","source":"# train_movies_scenes_subtitles, additional_train_data = associate_scenes_with_subtitles(train_full_data, train_movie_subtitles)\n# test_movies_scenes_subtitles, additional_test_data = associate_scenes_with_subtitles(test_full_data, test_movie_subtitles)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:21.507013Z","iopub.execute_input":"2024-01-26T18:04:21.507367Z","iopub.status.idle":"2024-01-26T18:04:21.511832Z","shell.execute_reply.started":"2024-01-26T18:04:21.507338Z","shell.execute_reply":"2024-01-26T18:04:21.510840Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Subtitles cleaning and combining","metadata":{}},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"code","source":"def clean_subtitles(movies_scenes_subtitles):\n    for movie_name, scenes in movies_scenes_subtitles.items():\n        for scene_id, subtitles in scenes.items():\n            cleaned_subtitles = []\n            for subtitle in subtitles:\n                # Remove new line characters\n                cleaned_subtitle = subtitle.replace('\\n', ' ').strip()\n                cleaned_subtitle = re.sub(r'<.*?>', '', cleaned_subtitle)\n                cleaned_subtitle = re.sub(r'♪', '', cleaned_subtitle)\n                cleaned_subtitles.append(cleaned_subtitle)\n            \n            combined_text = \" \".join(cleaned_subtitles)\n            movies_scenes_subtitles[movie_name][scene_id] = combined_text\n            \n    return movies_scenes_subtitles\n\ndef clean_subtitles_only_words(movies_scenes_subtitles):\n    for movie_name, scenes in movies_scenes_subtitles.items():\n        for scene_id, subtitles in scenes.items():\n            cleaned_subtitles = []\n            for subtitle in subtitles:\n                cleaned_subtitle = subtitle.replace('\\n', ' ').strip()\n                cleaned_subtitle = re.sub(r'<.*?>', '', cleaned_subtitle)\n                cleaned_subtitle = re.sub(r'[^a-zA-Z0-9\\s\\']', '', cleaned_subtitle)\n                cleaned_subtitles.append(cleaned_subtitle)\n            \n            combined_text = \" \".join(cleaned_subtitles)\n            movies_scenes_subtitles[movie_name][scene_id] = combined_text\n            \n    return movies_scenes_subtitles","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:21.846695Z","iopub.execute_input":"2024-01-26T18:04:21.847358Z","iopub.status.idle":"2024-01-26T18:04:21.856913Z","shell.execute_reply.started":"2024-01-26T18:04:21.847312Z","shell.execute_reply":"2024-01-26T18:04:21.855886Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# clean_train_movies_scenes_subtitles = clean_subtitles(train_movies_scenes_subtitles)\n# clean_train_movies_scenes_subtitles['four weddings and a funeral'][3]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:22.781205Z","iopub.execute_input":"2024-01-26T18:04:22.781869Z","iopub.status.idle":"2024-01-26T18:04:22.785368Z","shell.execute_reply.started":"2024-01-26T18:04:22.781836Z","shell.execute_reply":"2024-01-26T18:04:22.784493Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# clean_test_movies_scenes_subtitles = clean_subtitles(test_movies_scenes_subtitles)\n# clean_test_movies_scenes_subtitles['gone girl'][3]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:22.971754Z","iopub.execute_input":"2024-01-26T18:04:22.972483Z","iopub.status.idle":"2024-01-26T18:04:22.976216Z","shell.execute_reply.started":"2024-01-26T18:04:22.972451Z","shell.execute_reply":"2024-01-26T18:04:22.975267Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Text classification using BERT (Fourth Model)","metadata":{}},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"code","source":"unique_labels = train_full_data['label'].unique()\nlabel_to_int_mapping = {label: i for i, label in enumerate(unique_labels)}\nint_to_label_mapping = {i: label for label, i in label_to_int_mapping.items()}\n\ndef map_label_to_int(label):\n    return label_to_int_mapping[label]\n\n\ndef map_label_from_int(label):\n    return int_to_label_mapping[label] ","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:23.616357Z","iopub.execute_input":"2024-01-26T18:04:23.617259Z","iopub.status.idle":"2024-01-26T18:04:23.623405Z","shell.execute_reply.started":"2024-01-26T18:04:23.617225Z","shell.execute_reply":"2024-01-26T18:04:23.622480Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def transform_subtitles(subtitles, df):\n    transformed_subtitles = []\n    for movie_name, scenes in subtitles.items():\n        for scene_id, text in scenes.items():\n            # Get the label from train_full_data based on movie and scene_id\n            label = df[(df['movie'] == movie_name) & (df['scene_id'] == scene_id)]['label'].values[0]\n            label = map_label_to_int(label)\n            \n            result = {'text': text, 'label': label}\n            transformed_subtitles.append(result)\n    \n    return transformed_subtitles\n\n\ndef transform_validation_subtitles(subtitles, df):\n    transformed_subtitles = []\n    for movie_name, scenes in subtitles.items():\n        for scene_id, text in scenes.items():\n            result = {'text': text}\n            transformed_subtitles.append(result)\n    \n    return transformed_subtitles\n    \n\ndef print_head_transformed_subtitles(subtiltes):\n    for i in range(min(5, len(subtiltes))):\n        print(subtiltes[i])","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:24.345901Z","iopub.execute_input":"2024-01-26T18:04:24.346264Z","iopub.status.idle":"2024-01-26T18:04:24.354201Z","shell.execute_reply.started":"2024-01-26T18:04:24.346236Z","shell.execute_reply":"2024-01-26T18:04:24.353236Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_subtitles = associate_scenes_with_subtitles_extra_info(train_full_data, train_movie_subtitles, train_movie_scenes_count)\n# train_subtitles, _ = associate_scenes_with_subtitles(train_full_data, train_movie_subtitles)\nclean_train_subtitles = clean_subtitles_only_words(train_subtitles)\ntrain_transformed_subtitles = transform_subtitles(clean_train_subtitles, train_full_data)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:24.976176Z","iopub.execute_input":"2024-01-26T18:04:24.976940Z","iopub.status.idle":"2024-01-26T18:04:29.922477Z","shell.execute_reply.started":"2024-01-26T18:04:24.976910Z","shell.execute_reply":"2024-01-26T18:04:29.921695Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Ignored subtitltes: 3204\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_transformed_subtitles","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:29.923968Z","iopub.execute_input":"2024-01-26T18:04:29.924265Z","iopub.status.idle":"2024-01-26T18:04:29.928309Z","shell.execute_reply.started":"2024-01-26T18:04:29.924239Z","shell.execute_reply":"2024-01-26T18:04:29.927276Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"validation_subtitles = associate_scenes_with_subtitles_extra_info(test_full_data, test_movie_subtitles, test_movie_scenes_count)\n# validation_subtitles, _ = associate_scenes_with_subtitles(test_full_data, test_movie_subtitles)\nclean_validation_subtitles = clean_subtitles_only_words(validation_subtitles)\nvalidation_transformed_subtitles = transform_validation_subtitles(clean_validation_subtitles, test_full_data)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:29.929405Z","iopub.execute_input":"2024-01-26T18:04:29.929644Z","iopub.status.idle":"2024-01-26T18:04:30.422092Z","shell.execute_reply.started":"2024-01-26T18:04:29.929623Z","shell.execute_reply":"2024-01-26T18:04:30.421141Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Ignored subtitltes: 3165\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Extract 'text' and 'label' from each dictionary\ntexts = [item['text'] for item in train_transformed_subtitles]\nlabels = [item['label'] for item in train_transformed_subtitles]\n\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.3, random_state=42)\n\n# # Create training and testing datasets\ntrain_data = [{'text': text, 'label': label} for text, label in zip(train_texts, train_labels)]\ntest_data = [{'text': text, 'label': label} for text, label in zip(test_texts, test_labels)]\n# data = [{'text': text, 'label': label} for text, label in zip(texts, labels)]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:32.939435Z","iopub.execute_input":"2024-01-26T18:04:32.939782Z","iopub.status.idle":"2024-01-26T18:04:33.407925Z","shell.execute_reply.started":"2024-01-26T18:04:32.939754Z","shell.execute_reply":"2024-01-26T18:04:33.407113Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### For cross-validation","metadata":{}},{"cell_type":"code","source":"# texts = [item['text'] for item in train_transformed_subtitles]\n# labels = [item['label'] for item in train_transformed_subtitles]\n\n# data = [{'text': text, 'label': label} for text, label in zip(texts, labels)]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:35.370092Z","iopub.execute_input":"2024-01-26T18:04:35.370471Z","iopub.status.idle":"2024-01-26T18:04:35.374825Z","shell.execute_reply.started":"2024-01-26T18:04:35.370441Z","shell.execute_reply":"2024-01-26T18:04:35.373825Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### No cross validation","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\ntrain_dataset = Dataset.from_list(train_data)\ntest_dataset = Dataset.from_list(test_data)\nvalidation_dataset = Dataset.from_list(validation_transformed_subtitles)\n\nprint(train_dataset)\nprint(test_dataset)\nprint(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:36.402878Z","iopub.execute_input":"2024-01-26T18:04:36.403219Z","iopub.status.idle":"2024-01-26T18:04:36.497695Z","shell.execute_reply.started":"2024-01-26T18:04:36.403194Z","shell.execute_reply":"2024-01-26T18:04:36.496770Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 2784\n})\nDataset({\n    features: ['text', 'label'],\n    num_rows: 1194\n})\nDataset({\n    features: ['text'],\n    num_rows: 2470\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer\n\ndef choose_model(name):\n    if name == \"distilbert\": \n        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=16)\n    elif name == \"bert\":\n        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=16)\n    elif name == \"bert-large\":\n        tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=16)\n    elif name == \"roberta\":\n        tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=16)\n    elif name == \"roberta-large\":\n        tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=16)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n        model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=16)\n\n    return model, tokenizer\n\nmodel, tokenizer = choose_model(\"bert\")","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:27:19.015179Z","iopub.execute_input":"2024-01-26T18:27:19.015530Z","iopub.status.idle":"2024-01-26T18:27:19.644794Z","shell.execute_reply.started":"2024-01-26T18:27:19.015504Z","shell.execute_reply":"2024-01-26T18:27:19.643824Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import nltk\n# import subprocess\n\n# # Download and unzip wordnet\n# try:\n#     nltk.data.find('wordnet.zip')\n# except:\n#     nltk.download('wordnet', download_dir='/kaggle/working/')\n#     command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n#     subprocess.run(command.split())\n#     nltk.data.path.append('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:54.663515Z","iopub.execute_input":"2024-01-26T18:04:54.664575Z","iopub.status.idle":"2024-01-26T18:04:54.668846Z","shell.execute_reply.started":"2024-01-26T18:04:54.664532Z","shell.execute_reply":"2024-01-26T18:04:54.667937Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\n# nltk.data.path.append(\"/root/nltk_data\")\n\n# nltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n\ndef remove_stopwords_and_lemmatize(text):\n    words = text.split()\n    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n    return ' '.join(filtered_words)\n\n\ndef remove_stopwords(text):\n    words = text.split()\n    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n    return ' '.join(filtered_words)\n\n\ndef preprocess_function(examples):\n#     examples[\"text\"] = [remove_stopwords_and_lemmatize(text) for text in examples[\"text\"]]\n    examples[\"text\"] = [remove_stopwords(text) for text in examples[\"text\"]]\n    tokenized_text = tokenizer(examples[\"text\"], truncation=True)\n    \n    return tokenized_text","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:55.065288Z","iopub.execute_input":"2024-01-26T18:04:55.066070Z","iopub.status.idle":"2024-01-26T18:04:55.515591Z","shell.execute_reply.started":"2024-01-26T18:04:55.066025Z","shell.execute_reply":"2024-01-26T18:04:55.514774Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\ntokenized_validation_dataset = validation_dataset.map(preprocess_function, batched=True)\ntokenized_validation_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:55.948376Z","iopub.execute_input":"2024-01-26T18:04:55.948741Z","iopub.status.idle":"2024-01-26T18:04:57.344794Z","shell.execute_reply.started":"2024-01-26T18:04:55.948716Z","shell.execute_reply":"2024-01-26T18:04:57.343938Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2784 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea16fcb8d6c941fab46c2f47b5f2345a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1194 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc47839201c439c99a1f57490c28e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2470 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31376ae4e6754da9bb9dd8d94aefac10"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:58.306570Z","iopub.execute_input":"2024-01-26T18:04:58.306925Z","iopub.status.idle":"2024-01-26T18:04:58.312675Z","shell.execute_reply.started":"2024-01-26T18:04:58.306898Z","shell.execute_reply":"2024-01-26T18:04:58.311710Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2784\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:59.379856Z","iopub.execute_input":"2024-01-26T18:04:59.380184Z","iopub.status.idle":"2024-01-26T18:04:59.384592Z","shell.execute_reply.started":"2024-01-26T18:04:59.380160Z","shell.execute_reply":"2024-01-26T18:04:59.383601Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import evaluate\nmetric = evaluate.load('accuracy')\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:04:59.655743Z","iopub.execute_input":"2024-01-26T18:04:59.656374Z","iopub.status.idle":"2024-01-26T18:05:02.560913Z","shell.execute_reply.started":"2024-01-26T18:04:59.656333Z","shell.execute_reply":"2024-01-26T18:05:02.560030Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d432b3db6e74dd79116905341e62aeb"}},"metadata":{}}]},{"cell_type":"code","source":"%env JOBLIB_TEMP_FOLDER=/tmp","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:05:02.562820Z","iopub.execute_input":"2024-01-26T18:05:02.563470Z","iopub.status.idle":"2024-01-26T18:05:02.568208Z","shell.execute_reply.started":"2024-01-26T18:05:02.563434Z","shell.execute_reply":"2024-01-26T18:05:02.567361Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"env: JOBLIB_TEMP_FOLDER=/tmp\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Cross Validation","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import KFold\n\n# num_folds = 5\n# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:05:02.569734Z","iopub.execute_input":"2024-01-26T18:05:02.570084Z","iopub.status.idle":"2024-01-26T18:05:04.246135Z","shell.execute_reply.started":"2024-01-26T18:05:02.570048Z","shell.execute_reply":"2024-01-26T18:05:04.245325Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# all_predictions = []\n# for fold, (train_index, val_index) in enumerate(kf.split(tokenized_train_dataset)):\n#     print(f\"Training Fold {fold + 1}/{num_folds}\")\n\n#     model, _ = choose_model(\"roberta\")\n\n#     train_dataset_fold = tokenized_train_dataset.select(train_index)\n#     val_dataset_fold = tokenized_train_dataset.select(val_index)\n    \n#     training_args_fold = TrainingArguments(\n#         output_dir=f\"./results_fold_{fold}\",\n#         learning_rate=2e-5,\n#         per_device_train_batch_size=12,\n#         per_device_eval_batch_size=12,\n#         gradient_accumulation_steps=1,\n#         num_train_epochs=18,\n#         weight_decay=0.01,\n#         save_total_limit=2,\n#         load_best_model_at_end=True,\n#         save_strategy=\"epoch\",\n#         evaluation_strategy=\"epoch\",\n#         metric_for_best_model=\"eval_accuracy\"\n#     )\n\n#     trainer_fold = Trainer(\n#         model=model,\n#         args=training_args_fold,\n#         train_dataset=train_dataset_fold,\n#         eval_dataset=val_dataset_fold,\n#         tokenizer=tokenizer,\n#         data_collator=data_collator,\n#         compute_metrics=compute_metrics\n#     )\n\n#     trainer_fold.train()\n    \n#     predictions = trainer_fold.predict(val_dataset_fold)\n\n#     all_predictions.append(predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:05:04.248015Z","iopub.execute_input":"2024-01-26T18:05:04.248342Z","iopub.status.idle":"2024-01-26T18:05:04.259922Z","shell.execute_reply.started":"2024-01-26T18:05:04.248291Z","shell.execute_reply":"2024-01-26T18:05:04.259023Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# # Combine predictions from all folds\n# all_predictions_combined = np.array(all_predictions) \n# # Use np.argmax along axis 2 to get the index with the most votes for each instance\n# majority_votes = np.argmax(np.sum(all_predictions_combined, axis=0), axis=1)\n# final_predictions = majority_votes.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:05:04.260956Z","iopub.execute_input":"2024-01-26T18:05:04.261219Z","iopub.status.idle":"2024-01-26T18:05:04.270879Z","shell.execute_reply.started":"2024-01-26T18:05:04.261196Z","shell.execute_reply":"2024-01-26T18:05:04.270149Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# final_predictions","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:05:04.271890Z","iopub.execute_input":"2024-01-26T18:05:04.272179Z","iopub.status.idle":"2024-01-26T18:05:04.280792Z","shell.execute_reply.started":"2024-01-26T18:05:04.272156Z","shell.execute_reply":"2024-01-26T18:05:04.279937Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Split train and test data","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=1,\n    num_train_epochs=15,\n    weight_decay=0.01,\n#     logging_steps=100,\n    save_total_limit = 2,\n#     save_strategy=\"no\",\n#     save_steps=99999999999999999,\n    load_best_model_at_end = True,\n    save_strategy = \"epoch\",\n    evaluation_strategy = \"epoch\",\n    metric_for_best_model = \"eval_loss\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:27:28.788500Z","iopub.execute_input":"2024-01-26T18:27:28.788825Z","iopub.status.idle":"2024-01-26T18:43:02.734354Z","shell.execute_reply.started":"2024-01-26T18:27:28.788800Z","shell.execute_reply":"2024-01-26T18:43:02.733498Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5220' max='5220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5220/5220 15:32, Epoch 15/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.705404</td>\n      <td>0.445561</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.990400</td>\n      <td>1.531736</td>\n      <td>0.485762</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.564600</td>\n      <td>1.415444</td>\n      <td>0.497487</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.564600</td>\n      <td>1.321403</td>\n      <td>0.536013</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.367400</td>\n      <td>1.280802</td>\n      <td>0.553601</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.234900</td>\n      <td>1.203810</td>\n      <td>0.587102</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.234900</td>\n      <td>1.205725</td>\n      <td>0.597152</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.104900</td>\n      <td>1.161402</td>\n      <td>0.613903</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.999900</td>\n      <td>1.142840</td>\n      <td>0.626466</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.999900</td>\n      <td>1.144620</td>\n      <td>0.628141</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.905900</td>\n      <td>1.160251</td>\n      <td>0.614740</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.825700</td>\n      <td>1.170768</td>\n      <td>0.622278</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.752100</td>\n      <td>1.148058</td>\n      <td>0.613065</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.752100</td>\n      <td>1.159360</td>\n      <td>0.627303</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.709600</td>\n      <td>1.165313</td>\n      <td>0.616415</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5220, training_loss=1.1267297591286145, metrics={'train_runtime': 933.0523, 'train_samples_per_second': 44.756, 'train_steps_per_second': 5.595, 'total_flos': 3476253174826752.0, 'train_loss': 1.1267297591286145, 'epoch': 15.0})"},"metadata":{}}]},{"cell_type":"code","source":"# folder_path = \"/kaggle/working/results\"\n# def load_model(model_name):\n#     model_path = f\"{folder_path}/{model_name}\"\n#     tokenizer = AutoTokenizer.from_pretrained(model_path)\n#     model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    \n#     return tokenizer, model\n    \n# # loaded_model, loaded_tokenizer = load_model(\"checkpoint-3052\")","metadata":{"execution":{"iopub.status.busy":"2024-01-18T14:53:32.262975Z","iopub.execute_input":"2024-01-18T14:53:32.263871Z","iopub.status.idle":"2024-01-18T14:53:32.269436Z","shell.execute_reply.started":"2024-01-18T14:53:32.263836Z","shell.execute_reply":"2024-01-18T14:53:32.268275Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:43:14.524165Z","iopub.execute_input":"2024-01-26T18:43:14.524518Z","iopub.status.idle":"2024-01-26T18:43:21.256320Z","shell.execute_reply.started":"2024-01-26T18:43:14.524490Z","shell.execute_reply":"2024-01-26T18:43:21.255361Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.1428395509719849,\n 'eval_accuracy': 0.626465661641541,\n 'eval_runtime': 6.7185,\n 'eval_samples_per_second': 177.72,\n 'eval_steps_per_second': 22.327,\n 'epoch': 15.0}"},"metadata":{}}]},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:43:21.259867Z","iopub.execute_input":"2024-01-26T18:43:21.260170Z","iopub.status.idle":"2024-01-26T18:43:34.781863Z","shell.execute_reply.started":"2024-01-26T18:43:21.260143Z","shell.execute_reply":"2024-01-26T18:43:34.780755Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"predicted_probabilities = predictions.predictions\npredicted_label_ids = np.argmax(predicted_probabilities, axis=-1)\n\nlabel_predictions = [map_label_from_int(label) for label in predicted_label_ids]\nprint(f\"first 5 predictions: {label_predictions[:30]} \\nlast 5 predictions: {label_predictions[-30:]}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:43:34.783205Z","iopub.execute_input":"2024-01-26T18:43:34.783563Z","iopub.status.idle":"2024-01-26T18:43:34.793023Z","shell.execute_reply.started":"2024-01-26T18:43:34.783533Z","shell.execute_reply":"2024-01-26T18:43:34.791608Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"first 5 predictions: ['Opening Image', 'Opening Image', 'Opening Image', 'Set-Up', 'Set-Up', 'Set-Up', 'Set-Up', 'Set-Up', 'Set-Up', 'Set-Up', 'Set-Up', 'Debate', 'Set-Up', 'Debate', 'Debate', 'Debate', 'Debate', 'Debate', 'Debate', 'None', 'Debate', 'Debate', 'Debate', 'B Story', 'B Story', 'B Story', 'B Story', 'Fun and Games', 'Fun and Games', 'B Story'] \nlast 5 predictions: ['Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Finale', 'Final Image', 'Final Image', 'Final Image', 'Final Image', 'Final Image', 'Final Image']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Result data","metadata":{}},{"cell_type":"code","source":"result_df = pd.DataFrame(columns=['Id', 'Label'])\n\ndef fill_result_df(full_data, movies, movies_ids, predictions):\n    for idx, scene in full_data.iterrows():\n        movie_name = scene['movie']\n        movie_index = movies.index(movie_name)\n        movie_id = movies_ids[movie_index]\n        scene_id = scene['scene_id']\n        movie_scene_id = f\"{movie_id}_{scene_id}\"\n\n        pred_label = predictions[idx]\n        result_df.loc[idx] = [movie_scene_id, pred_label]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:43:34.795686Z","iopub.execute_input":"2024-01-26T18:43:34.796022Z","iopub.status.idle":"2024-01-26T18:43:34.807634Z","shell.execute_reply.started":"2024-01-26T18:43:34.795995Z","shell.execute_reply":"2024-01-26T18:43:34.806355Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"fill_result_df(test_full_data, test_movies, test_movies_ids, label_predictions)\n\nresult_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:43:34.809278Z","iopub.execute_input":"2024-01-26T18:43:34.810203Z","iopub.status.idle":"2024-01-26T18:43:37.138067Z","shell.execute_reply.started":"2024-01-26T18:43:34.810159Z","shell.execute_reply":"2024-01-26T18:43:37.137000Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"            Id          Label\n0  tt0822832_1  Opening Image\n1  tt0822832_2  Opening Image\n2  tt0822832_4  Opening Image\n3  tt0822832_6         Set-Up\n4  tt0822832_7         Set-Up","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0822832_1</td>\n      <td>Opening Image</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0822832_2</td>\n      <td>Opening Image</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0822832_4</td>\n      <td>Opening Image</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0822832_6</td>\n      <td>Set-Up</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0822832_7</td>\n      <td>Set-Up</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result_df.to_csv('output_bert__eval_loss.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T17:58:25.921384Z","iopub.execute_input":"2024-01-26T17:58:25.922187Z","iopub.status.idle":"2024-01-26T17:58:25.935622Z","shell.execute_reply.started":"2024-01-26T17:58:25.922154Z","shell.execute_reply":"2024-01-26T17:58:25.934607Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig\n\nfolder_name = \"results\"\n\ndef save_model(model, tokenizer, name):\n    model_folder_path = f\"./{folder_name}/{name}\" \n    model.save_model(model_folder_path)\n    tokenizer.save_pretrained(model_folder_path)\n    config = BertConfig.from_pretrained(model_folder_path)\n    config.save_pretrained(model_folder_path)\n    \n# save_model(trainer, tokenizer, \"model_large_roberta_5\")","metadata":{"execution":{"iopub.status.busy":"2024-01-17T21:33:55.813513Z","iopub.execute_input":"2024-01-17T21:33:55.813905Z","iopub.status.idle":"2024-01-17T21:33:55.821667Z","shell.execute_reply.started":"2024-01-17T21:33:55.813875Z","shell.execute_reply":"2024-01-17T21:33:55.820697Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clean memory","metadata":{}},{"cell_type":"code","source":"# import torch\n# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:17:34.380048Z","iopub.execute_input":"2024-01-17T19:17:34.380390Z","iopub.status.idle":"2024-01-17T19:17:34.388124Z","shell.execute_reply.started":"2024-01-17T19:17:34.380364Z","shell.execute_reply":"2024-01-17T19:17:34.387082Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# import gc\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:17:34.389498Z","iopub.execute_input":"2024-01-17T19:17:34.389853Z","iopub.status.idle":"2024-01-17T19:17:34.397770Z","shell.execute_reply.started":"2024-01-17T19:17:34.389808Z","shell.execute_reply":"2024-01-17T19:17:34.396753Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"## Save combined clean data in file","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"# output_file_path = \"output_combined_file.txt\"  # Set your desired output file\n\n# with open(output_file_path, 'w', encoding='utf-8') as output_file:\n#     for movie, scenes in clean_train_movies_scenes_subtitles.items():\n#         output_file.write(f\"======= {movie} =========\\n\\n\")\n#         output_file.write(str(scenes))\n\n# print(\"Combined text file saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:17:34.398834Z","iopub.execute_input":"2024-01-17T19:17:34.399124Z","iopub.status.idle":"2024-01-17T19:17:34.408893Z","shell.execute_reply.started":"2024-01-17T19:17:34.399100Z","shell.execute_reply":"2024-01-17T19:17:34.407882Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# output_file_path = \"output_combined_file2.txt\"  # Set your desired output file\n\n# with open(output_file_path, 'w', encoding='utf-8') as output_file:\n#     for movie, scenes in clean_train_subtitles.items():\n#         output_file.write(f\"======= {movie} =========\\n\\n\")\n#         output_file.write(str(scenes))\n\n# print(\"Combined text file saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:17:34.410094Z","iopub.execute_input":"2024-01-17T19:17:34.410412Z","iopub.status.idle":"2024-01-17T19:17:34.418508Z","shell.execute_reply.started":"2024-01-17T19:17:34.410380Z","shell.execute_reply":"2024-01-17T19:17:34.417555Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}